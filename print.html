<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Apunte Final Teoria de las Comunicaciones 2024</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="./custom.css">
        <link rel="stylesheet" href="./mdbook-admonish.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="unidad_0.html"><strong aria-hidden="true">1.</strong> Unidad 0 - Introducción, conceptos básicos</a></li><li class="chapter-item expanded "><a href="unidad_1.html"><strong aria-hidden="true">2.</strong> Unidad 1 - Nivel físico</a></li><li class="chapter-item expanded "><a href="unidad_2.html"><strong aria-hidden="true">3.</strong> Unidad 2 - Nivel de Enlace</a></li><li class="chapter-item expanded "><a href="unidad_3.html"><strong aria-hidden="true">4.</strong> Unidad 3 - Medios Compartidos</a></li><li class="chapter-item expanded "><a href="unidad_4.html"><strong aria-hidden="true">5.</strong> Unidad 4 - Nivel de Red</a></li><li class="chapter-item expanded "><a href="unidad_5.html"><strong aria-hidden="true">6.</strong> Unidad 5 - Ruteo</a></li><li class="chapter-item expanded "><a href="unidad_6.html"><strong aria-hidden="true">7.</strong> Unidad 6 - Nivel de Transporte</a></li><li class="chapter-item expanded "><a href="unidad_7.html"><strong aria-hidden="true">8.</strong> Unidad 7 - El problema de Congestión</a></li><li class="chapter-item expanded "><a href="unidad_8.html"><strong aria-hidden="true">9.</strong> Unidad 8 - Nivel de Aplicación</a></li><li class="chapter-item expanded "><a href="unidad_9.html"><strong aria-hidden="true">10.</strong> Unidad 9 - Seguridad</a></li><li class="chapter-item expanded "><a href="bibliografia.html"><strong aria-hidden="true">11.</strong> Bibliografía</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Apunte Final Teoria de las Comunicaciones 2024</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="unidad-0---introducción-conceptos-básicos"><a class="header" href="#unidad-0---introducción-conceptos-básicos">Unidad 0 - Introducción, conceptos básicos</a></h1>
<p>El primer invento similar a lo que conocemos hoy en día como redes de
comunicación fue la del telégrafo. Luego, le siguió la del teléfono, y ambos
tenían una cualidad que persistió hasta aproximadamente la década del 70: la
<strong>conmutación de circuitos</strong>.</p>
<p>La conmutación de circuitos como indica el nombre implicaba que haya operarios
encargados de conectar a las dos personas / aparatos que querían iniciar una
comunicación (cof cof, <em>operadora, comuníqueme con pirulito</em>)</p>
<p>Este approach tiene varias desventajas, por lo que mayoritariamente entre los
años 1959-1969 se desarrollaron las ideas que nos llevaron a la <strong>conmutación
de paquetes</strong>, cuyo objetivo principal era resultar en una red más tolerante a
fallas. Cómo se logró esto?</p>
<ul>
<li>Redundancia: que haya múltiples caminos entre dos puntos de la red</li>
<li>Descentralizada: toleracia a censura</li>
<li>División en fragmentos de los mensajes cosa de que puedan tomar caminos
diferentes.</li>
</ul>
<p><em>ARPANET</em> (Advanced Research Projects Agency Network) fue uno de los más importantes.</p>
<h2 id="estandarización"><a class="header" href="#estandarización">Estandarización</a></h2>
<p>Las tecnologías de redes con conmutación de paquetes se suiguieron
desarrollando, terminando a mediados de los 80 con una situación en la que
tenías muchas redes distintas cada una con su implementación particular y sus
propios detalles. Se empieza a hablar de la idea de tener una red única (en
mayo de 1983 ISO publica “ISO 7498:The Basic Reference Model for Open Systems
Interconnection” como un estándar internacional)</p>
<p><img src="./img/osi_model.png" alt="Diagrama Modelo OSI" /></p>
<p>El modelo OSI describe tódo lo que sucede con la información en una
comunicación entre dos puntos. Parte el proceso en 7 capas, en la que cada una
tiene un fin particular y cuyas entidades relevantes son definidas por eso. Por
ejemplo, en la capa de aplicación tu entidad puede ser un archivo mientras que
en la capa de de red tu entidad puede ser el paquete.</p>
<p>Si bien se usa el modelo OSI para estudiar teoría de comunicaciones, hoy en día
el verdadero ganador fue el modelo de TCP/IP, en donde hay 4 capas en lugar de
las 7 que propone OSI</p>
<p><img src="./osi_tcp_differences.png" alt="Diferencias OSI vs TCP/IP" /></p>
<div id="admonition-osi-the-internet-that-wasnthttpsspectrumieeeorgosi-the-internet-that-wasnt" class="admonition admonish-info">
<div class="admonition-title">
<p><a href="https://spectrum.ieee.org/osi-the-internet-that-wasnt">osi the internet that wasnt</a></p>
<p><a class="admonition-anchor-link" href="unidad_0.html#admonition-osi-the-internet-that-wasnthttpsspectrumieeeorgosi-the-internet-that-wasnt"></a></p>
</div>
<div>
<p>TLDR: OSI y TCP/IP compitieron durante un tiempo, pero una de las mayores
diferencias radicaba en que OSI era un protocolo que se estaba gestando por un
comité conformado por gente de la industria y cada uno quería tener su
influencia sobre el protocolo. Esto resultó en problemas para ponerse de
acuerdo y en un modelo que si bien era completo era mucho más difícil de
implementar, más caro y complejo.</p>
<p>Mientras seguían discutiendo sobre el estándar de OSI, TCP/IP ya se estaba usando...</p>
</div>
</div>
<h2 id="nivel-físico"><a class="header" href="#nivel-físico">Nivel Físico</a></h2>
<h3 id="sistema-de-comunicaciones"><a class="header" href="#sistema-de-comunicaciones">Sistema de Comunicaciones</a></h3>
<p>Modelo: tengo fuente de info -&gt; Emisor -&gt; ----- canal de comunicación ----- -&gt; Receptor -&gt; Destino</p>
<ul>
<li>Qué es información?</li>
<li>Qué es un canal?
<ul>
<li>guiado (cable)</li>
<li>no guiado (inalámbrico)</li>
</ul>
</li>
<li><strong>Siempre</strong> me ingresa ruido (alto o bajo)</li>
</ul>
<div id="admonition-ejemplo" class="admonition admonish-info">
<div class="admonition-title">
<p>Ejemplo</p>
<p><a class="admonition-anchor-link" href="unidad_0.html#admonition-ejemplo"></a></p>
</div>
<div>
<p>Hablo en meet y tengo a mi gato maullando. Tengo que hablar más fuerte. Más
fuerte = mejor? Bueno no, lo que importa es la relación entre cuánto grito y el
ruido ambiente.</p>
</div>
</div>
<ul>
<li>Relación Señal / Ruido</li>
<li>La señal tiende a atenuarse a mayor distancia. Si se achica la señal y el
ruido es constante, entonces se achica la capacidad de transmisión también.</li>
<li>Lo importante de señal:
<ul>
<li>Es una onda electromagnética</li>
<li>Se propaga a la velocidad de la luz (a un ~70% de la velocidad de la luz en el vacío)</li>
<li><em>Demora</em>, no es instantáneo (es un límite físico, no lo puedo evitar)
<ul>
<li><strong>Tiempo de propagación</strong></li>
<li>RTT (Round Trip Time) entre USA y ARG = 100ms</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Frecuencia \(f\) = Cantidad de ciclos que entran en un segundo</p>
<p>Longitud de onda \(\lambda\) = \(c\) (velocidad de la luz) \(/ f\)</p>
<ul>
<li>a mayor frecuencia menor longitud de onda (\(c\) es constante)</li>
</ul>
<p>Glosario:</p>
<ul>
<li>Amplitud</li>
<li>Frecuencia Angular (= \(2 \pi f\))</li>
<li>Frecuencia Temporal (\(f\))</li>
<li>Período = \(\frac{1}{f}\)</li>
<li>Fase (desplazamiento)</li>
</ul>
<h3 id="dominio-transformado"><a class="header" href="#dominio-transformado">Dominio Transformado</a></h3>
<p>Lo anterior era orientado al dominio del tiempo. Idea: paso ese dominio a otro para procesarlo mejor:</p>
<ul>
<li>serie trigonométrica de fourier -&gt; puedo representar ordas cuadradas como una serie infinita de senos y cosenos
<ul>
<li>permite descomponer la señal en las distintas frecuencias</li>
</ul>
</li>
<li>transformada de fourier
<ul>
<li>lo anterior en la teoría. Esto en la práctica</li>
<li>esto es lo que en la práctica permite descomponer una señal en sus distintas armónicas / componentes de frecuencia</li>
</ul>
</li>
</ul>
<h3 id="ancho-de-banda"><a class="header" href="#ancho-de-banda">Ancho de banda</a></h3>
<p>Rango de frecuencias senoidales que pueden pasar por el medio sin ser atenuadas (&lt; 3db, esto es una generalización).</p>
<div id="admonition-pregunta-de-final" class="admonition admonish-warning">
<div class="admonition-title">
<p>Pregunta de Final</p>
<p><a class="admonition-anchor-link" href="unidad_0.html#admonition-pregunta-de-final"></a></p>
</div>
<div>
<p>Tengo ancho de banda de 0 a 4 khz. Meto onda cuadrada periódica de 3khz en un canal con ancho de banda de 0 a 4khz. Qué obtengo a la salida?</p>
<p>Rta: Obtengo una onda senoidal de 3khz, porque la primera armónica tiene el
triple de frecuencia que la fundamental (en este caso es de 3 y la armónica ya
tiene 9), o sea que salvo la fundamental te filtra todo.</p>
</div>
</div>
<h3 id="teoría-de-la-información"><a class="header" href="#teoría-de-la-información">Teoría de la información</a></h3>
<p>(En el 48') Llega Shannon con su paper "A Mathematical Theory of
Communication". Ídolo, Genio, Maestro, Crack.</p>
<p>Idea fundamental:</p>
<ul>
<li>No interesa el significado del mensaje (No me importa si es teléfono, tele, internet, etc.)</li>
<li><strong>Teoría Clásica de la información</strong></li>
<li>Propone 2 teoremas fundamentales:
<ul>
<li>Codificación para una fuente sin ruido</li>
<li>Codificación para un canal con ruido</li>
</ul>
</li>
<li>Sorprendentemente nunca habla de cómo implementar nada</li>
</ul>
<p>Definición: qué es la información</p>
<p>$$
I(E) = log(\frac{1}{P(E)})
$$</p>
<p>La información que me da un evento es el logaritmo de la inversa de la
probabilidad de que ese evento suceda.</p>
<p><strong>Unidades</strong>:</p>
<ul>
<li>log en base 2? <em>1 bit</em> (por qué? Si tengo un dígito binario equiprobable \(I(\)sale 0/1\() = 1\)</li>
<li>(hay otros)</li>
</ul>
<h3 id="fuente-de-memoria-nula"><a class="header" href="#fuente-de-memoria-nula">Fuente de Memoria Nula</a></h3>
<p>Es el modelo que tomamos asumiendo que cada símbolo que emite es estadísticamente independiente del siguiente</p>
<div id="admonition-info" class="admonition admonish-info">
<div class="admonition-title">
<p>Info</p>
<p><a class="admonition-anchor-link" href="unidad_0.html#admonition-info"></a></p>
</div>
<div>
<p>Con una fuente de memoria nula, \(E(s_i) = log(\frac{1}{P(s_i)})\) bits</p>
</div>
</div>
<h3 id="entropía"><a class="header" href="#entropía">Entropía</a></h3>
<p>Viene a representar algo así como la cantidad media de info por símbolo de la fuente (similar a Esperanza).</p>
<p>$$
\sum_S P(s_i)I(s_i) \text{  bits}
$$</p>
<p>Es algo como la cantidad de info que voy a obtener cuando observo un símbolo / evento.</p>
<p>Cuándo maximizo la info que me van a dar los eventos? Cuando los eventos son equiprobables.</p>
<div id="admonition-offtopic-recomendación" class="admonition admonish-info">
<div class="admonition-title">
<p>offtopic recomendación</p>
<p><a class="admonition-anchor-link" href="unidad_0.html#admonition-offtopic-recomendación"></a></p>
</div>
<div>
<p>3b1b tiene un video en el que habla de entropía y lo aplica al wordle</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/v68zYyaEmEA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
</div>
<h3 id="extensión-de-la-fuente-de-memoria-nula"><a class="header" href="#extensión-de-la-fuente-de-memoria-nula">Extensión de la Fuente de Memoria Nula</a></h3>
<p>En vez de considerar de a un bit, agrupo varios bits juntos</p>
<h3 id="codificación"><a class="header" href="#codificación">Codificación</a></h3>
<p>Codificación sería el proceso por el cual mappeamos los símbolos de la fuente a
símbolos de un alfabeto asociado. Por qué hacemos esto? En primer lugar porque
a veces no tenemos una representación sencilla con la que trabajar. Y segundo
porque dependiendo el tipo de codificación que usemos vamos a obtener una mejor
o peor eficiencia.</p>
<ul>
<li>Le decimos <strong>código bloque</strong> a una codificación que asigna cada símbolo de la
fuente a una secuencia de símbolos del alfabeto destino.</li>
<li>Si la codificación es una función <strong>inyectiva</strong>, decimos que la codificación
es <strong>no singular</strong></li>
<li>Y decimos que una codificación es <strong>unívocamente decodificable</strong> si ninguna
tira de símbolos del código (o sea los códigos generados) admite más de una
única decodificación.</li>
<li>Por último, decímos que un código es <strong>instantáneo</strong> si es posible
decodificar sin ver los símbolos que suceden (no tiene que hacer look ahead)</li>
</ul>
<div id="admonition-condicion-de-los-prefijos" class="admonition admonish-info">
<div class="admonition-title">
<p>condicion de los prefijos</p>
<p><a class="admonition-anchor-link" href="unidad_0.html#admonition-condicion-de-los-prefijos"></a></p>
</div>
<div>
<p>Una condición <strong>necesaria y suficiente</strong> para que un código sea
<strong>instantáneo</strong>, es que no haya palabra en el alfabeto que sea prefijo de la
misma. Ojo, dos palabras pueden tener un mismo prefijo común siempre que el
mismo no pertenezca al alfabeto.</p>
<p>Teorema: Instantáneo =&gt; unívocamente decodificable</p>
</div>
</div>
<ul>
<li>En ascii tenemos 8 digitos binarios por símbolo</li>
<li>Sin embargo, en morse tenemos una cantidad variable</li>
</ul>
<p>Pensemos ahora que lo que mandamos son mensajes, y para representar cada
mensaje (\(m_i\)) lo representamos con una palabra de longitud \(L_i\). Y
nuestro símbolo se codifica con cadenas de un alfabeto de \(r\) símbolos.</p>
<p>Para esto último se define la <strong>longitud media de un código</strong>. Es la
probabilidad de ocurrencia de cada símbolo por su longitud. Sería como la
esperanza de la longitud de recibir un símbolo, o algo así.</p>
<p>$$
L = \sum{p_i L_i}
$$</p>
<p>Cómo lo minimizo? Al que más probabilidad tenga, le doy el código más chico.</p>
<p>Otra cosa más, es que para asegurar que no haya pérdida de información requiero
que:</p>
<p>$$
L log(r) \geq H(S)
$$</p>
<p>Donde \(log(r)\) es la cantidad promedio máxima de info de un símbolo del código (por lo que vimos antes).</p>
<p>Definimos con esa desigualdad la <strong>eficiencia de un código</strong> \(h\) como:</p>
<p>$$
h = \frac{H(s)}{L log(r)}
$$</p>
<p>y \(h_{max} = 1\)</p>
<h3 id="codificación-de-huffmann"><a class="header" href="#codificación-de-huffmann">Codificación de Huffmann</a></h3>
<p>Es un método que permite construir codificadores óptimos en base a la
frecuencia en la que aparecen los símbolos (de la fuente).</p>
<h2 id="medios-de-transmisión-reales"><a class="header" href="#medios-de-transmisión-reales">Medios de Transmisión Reales</a></h2>
<p>Cualquier canal de comunicación:</p>
<ul>
<li>Está expuesto a ruido</li>
<li>Tiene problemas de potencia</li>
<li>Tienen problemas de ancho de banda</li>
</ul>
<h3 id="fórmula-de-capacidad-de-shannon-para-un-canal-sujeto-a-ruido"><a class="header" href="#fórmula-de-capacidad-de-shannon-para-un-canal-sujeto-a-ruido">Fórmula de capacidad de Shannon para un canal sujeto a ruido</a></h3>
<p>$$
C_max(bps) = B(\text{hz}) log_2(1 + \text{SNR})
$$</p>
<div id="admonition-snr-para-capacidad-de-shannon" class="admonition admonish-info">
<div class="admonition-title">
<p>SNR para capacidad de Shannon</p>
<p><a class="admonition-anchor-link" href="unidad_0.html#admonition-snr-para-capacidad-de-shannon"></a></p>
</div>
<div>
<p>La relación señal-ruido de la capacidad de Shannon se expresa como logaritmos:</p>
<p>$$
SNR_{db} = 10 log_{10}(\text{SNR}) = 10 log_{10}(\frac{\text{PotenciaSeñal}}{\text{PotenciaRuido}})
$$</p>
<p>Por qué la escala logarítmica?</p>
<p>Es para ajustarse a las magnitudes. La atenuación es logarítmica, el oido tiene
respuesta logarítmica, etc. Y la escala logarítmica resulta más práctico (sobre
todo para visualizar)</p>
</div>
</div>
<h3 id="intro-a-nyquist"><a class="header" href="#intro-a-nyquist">Intro a Nyquist</a></h3>
<p>El ñato este tiró una fórmula para la capacidad máxima en canales <strong>sin ruido</strong>:</p>
<ul>
<li>
<p>2 niveles:
$$
C = 2B(\text{Hz})
$$</p>
</li>
<li>
<p>\(M\) niveles:
$$
C = 2B(\text{Hz})log_2(M)
$$</p>
</li>
</ul>
<p>Sin embargo hay una restricción, \(M\) tiene que ser más chico que \(\sqrt(1 + \text{SNR})\)</p>
<div id="admonition-pregunta-de-final-alert" class="admonition admonish-warning">
<div class="admonition-title">
<p>Pregunta de final alert</p>
<p><a class="admonition-anchor-link" href="unidad_0.html#admonition-pregunta-de-final-alert"></a></p>
</div>
<div>
<p><strong>Qué es el delay?</strong></p>
<p>Está formado por:</p>
<ul>
<li>el tiempo de propagación</li>
<li>el tiempo de transmisión</li>
<li>el tiempo de encolamiento</li>
<li>el tiempo de procesamiento</li>
</ul>
<p>Notar que sólo el tiempo de propagación ya te puede estar limitando porque
transmitimos casi a la velocidad de la luz y sin embargo para mandar 1 bit por
10000km por fibra tengo un tiempo de propagación aproximado de 50ms (y por lo
tanto 100ms de RTT).</p>
</div>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unidad-1---nivel-físico"><a class="header" href="#unidad-1---nivel-físico">Unidad 1 - Nivel Físico</a></h1>
<p>La fórmula de Shannon pone un límite en la tasa de transmisión, pero no en la
probabilidad de error. En teoría se podría minimizar arbitrariamente la
probabilidad de error usando una codificación lo suficientemente combleja y
obviamente con \(R_b \leq C\). Al no cumplir esto último esa idea de
minimizar la probabilidad de error arbitrariamente ya no es posible.</p>
<p><img src="./img/shannon_limit_graph.png#center" alt="Gráfico de SNR en base a la relación de la capacidad y el ancho de banda" /></p>
<p>Si graficamos la relación entre la SNR y la relación capacidad sobre ancho de
banda obtenemos el gráfico de arriba, que de alguna forma nos da valores para
lo que es posible y lo que no. En la práctica se busca asemejarse lo más
posible a la función graficada, buscando aumentar la cantidad de bits/s.</p>
<div id="admonition-pregunta-de-final" class="admonition admonish-warning">
<div class="admonition-title">
<p>pregunta de final</p>
<p><a class="admonition-anchor-link" href="unidad_1.html#admonition-pregunta-de-final"></a></p>
</div>
<div>
<p>Tengo un canal de ancho de banda de 0 a 2 Mhz, cuál es la forma de la onda de
salida si inyecto una señal de 1 Mhz. Sólamente obtengo la fundamental ya que a
partir de la tercer armónica que no entra en el ancho de banda.</p>
</div>
</div>
<h2 id="medios-de-transmisión"><a class="header" href="#medios-de-transmisión">Medios de transmisión</a></h2>
<p>Hoy en día tenemos internet compuesta por provedores que tiene tecnologías de acceso:</p>
<ul>
<li>Fibra</li>
<li>Cable</li>
<li>Satélite</li>
<li>Wifi</li>
<li>Celular</li>
</ul>
<p><img src="./img/internet_diagram.png#center" alt="Gráfico de organización de Internet" /></p>
<p>Las ondas electromagnéticas "necesitan" (en realidad no necesitan nada, se
pueden propagar por el vacío) un <strong>medio de transmisión</strong> por el cuál
transmitirse. Pueden ser:</p>
<ul>
<li>Guiados: Cable
<ul>
<li>de cobre</li>
<li>coaxil</li>
<li>fibra óptica</li>
</ul>
</li>
<li>No guiados: El espacio, libre
<ul>
<li>por radio</li>
<li>microondas</li>
<li>ondas infrarojas</li>
<li>laser</li>
<li>satélite</li>
<li>luz</li>
</ul>
</li>
</ul>
<h2 id="red-telefónica"><a class="header" href="#red-telefónica">Red telefónica</a></h2>
<p>Vamos a tomar de ejemplo a la red telefónica ya que muchos de los conceptos se
replican en otros medios de tecnologías.</p>
<ul>
<li>mediante conmutación de circuitos</li>
</ul>
<h3 id="multiplexación"><a class="header" href="#multiplexación">Multiplexación</a></h3>
<p>Multiplexar consiste en poder tener varias comunicaciones simultáneas en un
mismo troncal físico.</p>
<p>Podemos multiplexar:</p>
<ul>
<li>por tiempo: una suerte de round robin</li>
<li>por división frecuencia: transmito a través de las distintas bandas
<ul>
<li>el circuito para esto suele ser más complejo</li>
<li>al tener menos ancho de banda es "más lento", pero tengo más uptime</li>
</ul>
</li>
<li>por división de onda: lo mismo que antes pero aplicado a sistemas ópticos</li>
</ul>
<p><img src="./img/multiplexation_time_vs_freq.png#center" alt="Multiplexación por Frecuencia vs Tiempo" /></p>
<h2 id="taxonomía-de-redes"><a class="header" href="#taxonomía-de-redes">Taxonomía de Redes</a></h2>
<p>Las Redes de comunicaciones se pueden dividir en:</p>
<ul>
<li>Redes de conmutación de Circuitos</li>
<li>Redes de conmutación de Paquetes
<ul>
<li>Redes con Circuitos Virtuales</li>
<li>Redes de Datagramas (en el 99.999% de la materia vemos esto)
<ul>
<li>servicio sin conexión</li>
<li>el nivel de transporte brinda soporte para dar servicio orientado a conexión también (ej: TCP)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Las redes de conmutación de paquetes se basan en el concepto de
<strong>multiplexación estadística</strong>. Mi conmutador tiene un buffer y despacha de a
poco en base a algún criterio en base a la dirección origen y destino de dichos
paquetes.</p>
<p>Esta idea también implica que cada paquete compite con otros por ser enviado y
puede llevarnos a situaciones de congestión.</p>
<h2 id="conversión-analógico-digital"><a class="header" href="#conversión-analógico-digital">Conversión Analógico Digital</a></h2>
<p>Tengo 2 Etapas:</p>
<ol>
<li>Primero una etapa de muestreo
<ul>
<li>Gracias a Nyquist sabemos que debemos muestrear al doble del ancho de banda (por lo menos)</li>
<li>Además, tengo que definir con cuántos dígitos binarios uso para representar cada muestra</li>
</ul>
</li>
<li>Segundo cuantifico dichas muestras (o sea mando el valor a su representación binaria correspondiente)
<ul>
<li>Hoy en día a esa técnica la llamamos <em>PCM</em> (<strong>P</strong>ulse <strong>C</strong>ode <strong>M</strong>odulation)</li>
</ul>
</li>
</ol>
<h3 id="teorema-del-muestreo-nyquist"><a class="header" href="#teorema-del-muestreo-nyquist">Teorema del muestreo (Nyquist)</a></h3>
<p>Si queremos Reconstruir una señal cuya frecuencia máxima es \(f_m\) debemos
muestrar dicha señal a una razón de \(f_s &gt; 2 * f_m\) llamada <strong>frecuencia de
muestreo</strong></p>
<div id="admonition-ejemplo-con-red-de-computadoras" class="admonition admonish-info">
<div class="admonition-title">
<p>Ejemplo con red de computadoras</p>
<p><a class="admonition-anchor-link" href="unidad_1.html#admonition-ejemplo-con-red-de-computadoras"></a></p>
</div>
<div>
<p><img src="./img/modem_and_codec.png#center" alt="" /></p>
<p>Este es un diagrama (un poco antiguo). Las oficinas interurbanas operaban en
digital, por lo que era necesario que la señal originalmente analógica sea
convertida a una señal digital.</p>
<p>Uno en casa entonces tenía un modem, que emitía una señal analógica y luego le
seguía un codec que se encargaba de hacer la conversión analógico digital. Del
otro lado de la red, estaba un codec que cumplía la función inversa y un modem
por cliente.</p>
<p>Si lo pensamos con el caso del teléfono, la mayoría de las comunicaciones por
voz se pueden agrupar en el rando de 0-4Khz, por lo tanto se necesita una tasa
de muestreo de 8Khz o 8000 muestras por segundo. Como en ese caso cada muestra
se codificaba en 8 bits (En realidad son 7 bits para la data y 1 para
sincronización), era necesario un ancho de banda (I know, está mal usar este
término) de 64kbps.</p>
</div>
</div>
<h2 id="modulación"><a class="header" href="#modulación">Modulación</a></h2>
<h3 id="frecuencia-modulada-vs-amplitud-modulada"><a class="header" href="#frecuencia-modulada-vs-amplitud-modulada">Frecuencia Modulada vs Amplitud Modulada</a></h3>
<p><img src="./img/am_vs_fm.png" alt="" /></p>
<p>Tengo la Señal Portadora y la Señal Modulante.</p>
<ul>
<li>Frecuencia Modulada es cuando la frecuencia de la portadora varía en base a la amplitud de la modulante.</li>
<li>Amplitud Modulada es cuando la amplitud de la portadora varía en base a la amplitud de la modulante.</li>
</ul>
<h3 id="modem"><a class="header" href="#modem">Modem</a></h3>
<p>Si volvemos al diagrama, la idea del modem era transformar la señal digital de
la computadora en una señal analógica para poder mandarla por los cables de
cobre (y posteriormente volver a ser convertida a digital por el codec 🤷).</p>
<p>El truco de los modems entonces es meter la información sobre una señal portadora que pueda pasar por el ancho de banda disponible. Para esto hay 3 técnicas de modulación de una señal digital sobre una analógica:</p>
<ul>
<li>Desplazamiento de amplitud (ASK)</li>
</ul>
<p><img src="./img/ask.png#center" alt="" /></p>
<ul>
<li>Desplazamiento de frecuencia (FSK)</li>
</ul>
<p><img src="./img/fsk.png#center" alt="" /></p>
<ul>
<li>Desplazamiento de fase (PSK)</li>
</ul>
<p><img src="./img/psk.png#center" alt="" /></p>
<ul>
<li>
<p><strong>Velocidad de Modulación</strong> \(V_m\): es el número de cambios de señal por unidad de
tiempo. Se mide en Baudios (símbolos / segundo).</p>
</li>
<li>
<p><strong>Velocidad de Transmisión</strong>: \(V_m * N\), donde \(N\) es el número de
bits por símbolo. Se mide en bits por segundo.</p>
</li>
</ul>
<h3 id="lets-go-even-further"><a class="header" href="#lets-go-even-further">Let's go even further</a></h3>
<blockquote>
<p>Recomendación: si tienen dudas lean esta parte del Tanenbaum, en el Peterson no está.</p>
</blockquote>
<p>Vieron que dijimos que la velocidad de Modulación la medimos en símbolos por
segundo, y no en base a la cantidad de bits. Bueno, tranquilamente podemos
asumir que no tengo un único canal binario si no muchos (varios bits), y la
combinación son los distintos símbolos a transferir.</p>
<p>Luego, lo que puedo hacer es modular para 2 bits en base a 4 frecuencias o 4 fases (QPSK) por
ejemplo. Esto es lo que se conoce como modulación multinivel.</p>
<p>También puedo combinar amplitud y fase (QAM) o amplitud y frecuencia (no puedo ambos
porque fase y frecuencia están relacionados). (hoy en día ya estamos llegando a 1024-QAM y 4096-QAM)</p>
<p><img src="./img/qpsk_and_gam.png#center" alt="" /></p>
<p>Y puedo agregar tantos niveles como quiera, pero fijate que a medida que agrego
más puntos, hago más finita la cuadratura. Con lo cual es más vulnerable al
ruido.</p>
<p>El error generado se llama <em>MER</em>, y se expresa en db como:</p>
<p>$$
\text{MER} = 10 log \frac{\text{RMS error magnitude}}{\text{average symbol magnitude}}
$$</p>
<div id="admonition-dato-de-color-sobre-wi-fi" class="admonition admonish-info">
<div class="admonition-title">
<p>Dato de color sobre Wi-Fi</p>
<p><a class="admonition-anchor-link" href="unidad_1.html#admonition-dato-de-color-sobre-wi-fi"></a></p>
</div>
<div>
<p>A medida que me alejo del router y pierdo señal, aumenta la <em>SNR</em> y por ende me
cuesta más distinguir cada símbolo de QAM. Entonces lo que hace Wi-Fi es
achicar la cantidad de símbolos y por ende baja de QAM-1024 (ponele) a QAM-256,
y por ende baja su velocidad para evitar errores en la transmisión.</p>
</div>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unidad-2---nivel-de-enlace"><a class="header" href="#unidad-2---nivel-de-enlace">Unidad 2 - Nivel de Enlace</a></h1>
<p>Tanto OSI como TCP usan un modelo basado en <em>capas</em>. Cada Entidad separa su
funcionalidad en varias capas. Cada capa agrega info de control, mediante el
agregado de headers. De esta forma la capa agrega / interpreta los headers o
frames enviados / recibidos y permite que haya una comunicación entre las capas
adyacentes pero a su vez capa a capa entre los distintos hosts.</p>
<p><img src="./img/control_info.png" alt="" /></p>
<p>Además, el servicio que una capa le brinda a otra se puede clasificar en:</p>
<ul>
<li><strong>sin conexión y sin reconocimiento</strong> (ej: UDP)</li>
<li><strong>sin conexión y con reconocimiento</strong> (ej: uso de ACK en capa 2 de OSI)</li>
<li><strong>orientado a conexión</strong> (ej: websockets, TCP)</li>
</ul>
<p>El objetivo de los protocolos de comunicación (nivel de enlace en OSI), buscan en proveer:</p>
<ul>
<li>confiabilidad</li>
<li>control de errores</li>
<li>control de flujo</li>
</ul>
<p>Un ejemplo para garantizar control de errores sería agregar un CRC / checksum
que el receptor valida. Si el receptor detecta que el mensaje es inválido,
basta con que no mande un ACK (aknowledge) de que recibió el mensaje.</p>
<h2 id="control-de-errores"><a class="header" href="#control-de-errores">Control de errores</a></h2>
<p>Si consideramos que lo que mandamos son <em>codewords</em> de \(n\) bits, compuestos
por \(m\) bits de datos y \(r\) bits de redundancia y siendo \(d\) la
distancia mínima de Hamming entre 2 codewords posibles y \(e\) la cantidad de
bits erroneos para un cierto mensjae, necesitamos que se cumpla que:</p>
<ul>
<li>\(e + 1 \leq d\) para poder detectar que hubo errores</li>
<li>\(2*e + 1 \leq d\) para poder corregir errores</li>
</ul>
<blockquote>
<p>Si quieren ver un algoritmo para detección y corrección de errores pueden
chequear
<a href="https://www.cs.cmu.edu/~guyb/realworld/reedsolomon/reed_solomon_codes.html">Reed-Solomon</a></p>
</blockquote>
<h2 id="confiabilidad"><a class="header" href="#confiabilidad">Confiabilidad</a></h2>
<p>Para garantizar confiabilidad, va a ser necesario poder efectuar
<em>retransmisiones</em>. Esto se puede dar de forma <strong>implícita</strong> cuando se produce
un <strong>timeout</strong> (tiempo sin recibir un ACK de que se recibió el mensaje), o de
forma <strong>explícita</strong> si nuestro protocolo admite mensajes de control.</p>
<p>Cómo puedo hacer el ACK de cierto símbolo? Mediante números de secuencia. El
ACK entonces representa que el frame con cierto número de secuencia fue
recibido.</p>
<h3 id="primer-approach-stop-and-wait"><a class="header" href="#primer-approach-stop-and-wait">Primer approach: Stop and Wait</a></h3>
<ul>
<li>Espero a recibir el ACK para mandar el nuevo frame.</li>
<li>Dado que es "bloqueante", basta con tener un único bit para el número de secuencia.</li>
</ul>
<p>Qué pasa si ocurre lo siguiente:</p>
<ol>
<li>El emisor manda el primer frame</li>
<li>Transcurre el tiempo suficiente para que ocurra un timeout (en el medio el
Receptor recibe el frame pero no responde a tiempo)</li>
<li>El emisor vuelve a mandar el primer frame</li>
<li>El emisor recibe el ACK del primer frame</li>
<li>El receptor recibe el primer frame y manda el ACK</li>
<li>El emisor recibe por segunda vez el ACK del primer frame</li>
</ol>
<p>Ese fenómeno es lo que se conoce como el <strong>problema del solapamiento</strong> o el
<strong>problema de las reencarnaciones</strong>, y los distintos approaches van a buscar
problemas de lidiar con esto.</p>
<h3 id="eficiencia-de-un-protocolo"><a class="header" href="#eficiencia-de-un-protocolo">Eficiencia de un protocolo</a></h3>
<p>Queremos evaluar cuánto tiempo se está transmitiendo vs cuánto tiempo se está
esperando por confirmaciones. Lo definimos como:</p>
<p>$$
\eta_{proto} = \frac{T_{tx}}{\text{RTT}(F)}
$$</p>
<blockquote>
<p>Pregunta: Tiene sentido que \(\eta_{proto} &gt; 1\)?</p>
</blockquote>
<h3 id="segundo-approach-ventana-deslizante"><a class="header" href="#segundo-approach-ventana-deslizante">Segundo approach: Ventana deslizante</a></h3>
<p>Para el caso de Stop and Wait, notar que transmito la mitad de lo que dura el
RTT y después espero, entonces tengo una eficiencia del 0,5. Queremos hacerlo
mejor.</p>
<p>Idea: mando varios frames seguidos, sin esperar al ACK. Esto es el concepto de
<strong>ventana de frames</strong>, y en ese caso el cálculo de la eficiencia cambia
ligeramente:</p>
<p>$$
\eta_{proto} = \frac{T_{tx}(V)}{\text{RTT}(F)}
$$</p>
<p>Ahora el \(T_{tx}(V)\) es el tiempo que me tarda mandar todos los frames de
la ventana, mientras que el \(\text{RTT}(F)\) es lo que tarda en volverme el
ACK del primer frame que mandé.</p>
<ul>
<li>Requiero de más bits para el número de secuencia (tiene que permitirme
identificar todos los frames de la trama por lo menos)</li>
<li>A medida que recibo los ACk voy desplazando la ventana (ojo porque ahora hay
que determinar cuándo desplazo la ventana. Siempre que recibo? O sólo si
recibí el siguiente al último que tenía reconocido?)</li>
</ul>
<p>Para buscar la mejor eficiencia posible se define como tamaño de ventana (en
frames) a:</p>
<p>$$
\text{SWS} = \frac{V_{tx} * RTT}{|Frame|}
$$</p>
<p>Y envío un frame nuevo siempre que \(\text{UltimoFrameEnviado} \leq \text{UltimoFrameReconocido} + \text{SWS}\)</p>
<h3 id="acks-acumulativos-vs-selectivos"><a class="header" href="#acks-acumulativos-vs-selectivos">ACKs acumulativos vs selectivos</a></h3>
<p>En la sección anterior faltó mencionar cuál es el comportamiento esperado del
receptor ante algún error. El primer approach es el de ACKs acumulativos, en
donde a partir de que se produce un error en la transmisión el receptor ignora
todos los mensajes posteriores hasta que el frame con error se reenvía y recibe
correctamente. (Esta idea de retransmitir todo se lo conoce también como
<strong>GoBackN</strong>)</p>
<p><img src="./img/sliding_window_gobackn.png#center" alt="" /></p>
<p>Ahora, también podría pedir que el receptor tenga un buffer que permita guardar
los frames que va recibiendo, y en ese caso basta con que el receptor mande una
señal pidiendo el frame específico.</p>
<p><img src="./img/sliding_window_sack.png#center" alt="" /></p>
<p>Para ambos casos definimos la ventana de recepción \(\text{RWS}\) como:</p>
<p>$$
\text{RWS} =
\begin{cases}
\text{SWS},  &amp; \text{si hay SACK} \\
1, &amp; \text{en caso contrario}
\end{cases}
$$</p>
<p>Además, como se puede dar acá también el problema de las reencarnaciones, es
necesario poder distinguir por lo menos \(SWS + RWS\) frames distintos.</p>
<h3 id="sobre-la-eficiencia-de-la-ventana"><a class="header" href="#sobre-la-eficiencia-de-la-ventana">Sobre la eficiencia de la ventana</a></h3>
<p>Primero necesito que definamos algunos conceptos:</p>
<ul>
<li>El <strong>tiempo de transmisión</strong> \(T_{tx} = \frac{|datos|}{V_{tx}}\) es el
tiempo para enviar todos los bits de un frame a través del medio de
transmisión.
<ul>
<li>Ocupa una porción significativa de tiempo en conexiones lentas o donde el
frame es muy grande.</li>
</ul>
</li>
<li>El <strong>tiempo de propagación</strong> \(T_{prop} = \frac{distancia}{V_{prop}}\) es
el tiempo desde que el bit es transmitido hasta que llega al receptor.
<ul>
<li>La velocidad de propagación \(V_{prop}\) es algo propio del medio de
transmisión, por lo general cercano a la velocidad de la luz (suele ser
una constante multiplicada por la velocidad de la luz).</li>
<li>Ocupa una porción significativa de tiempo en conexiones entre dos puntos
muy lejanos.</li>
</ul>
</li>
<li>El <strong>tiempo de encolamiento</strong> \(T_{queue}\) es el tiempo que espera un
frame en un buffer hasta ser transmitido. Dependiendo del estado de
congestión de la red puede ser significativo o no.</li>
<li>El <strong>tiempo de procesamiento</strong> \(T_{proc}\) es el tiempo que se tarda en
leer el header de un frame y decidir qué hacer con él. En la práctica se lo
asume nulo o poco significativo.</li>
</ul>
<p>Por último, la <strong>capacidad de volumen</strong> \(C_{vol}\) de un canal sería la cantidad de bits
que entran en el canal desde que se envía el primer bit hasta que llega al
receptor (una suerte de flujo máximo de bits para quienes hayan cursado algo
III).</p>
<p>$$
C_{vol} = \text{Delay} * V_{tx}
$$</p>
<p>Sin embargo, para los protocolos punto a punto se es un poco más
específico y se mide como la cantidad de bits que entran <strong>hasta recibir el
primer ACK</strong></p>
<p>$$
C_{vol} = \text{RTT} * V_{tx}
$$</p>
<p>(Recuerdo: antes mencionamos que el tamaño óptimo de ventana era \(SWS = \frac{\text{RTT} * V_{tx}}{|frame|} = \frac{C_{vol}}{|frame|}\))</p>
<p>Entonces... ¿Por qué es óptimo?</p>
<p>Recordamos que la eficiencia del protocolo de ventana deslizante se medía como:</p>
<p>$$
\eta_{proto} = \frac{T_{tx}(V)}{\text{RTT}(F)}
$$</p>
<p>\(T_{tx}(V)\) Era el tiempo que tardaba en mandar todos los frames de la ventana. Eso lo podemos pensar como:</p>
<p>$$
T_{tx}(V) = \frac{SWS * |frame|}{V_{tx}}
$$</p>
<p>Entonces:</p>
<p>$$
\eta_{proto} = \frac{SWS * |frame|}{V_{tx} * \text{RTT}(F)} \\
SWS = \eta_{proto} * \frac{V_{tx} * \text{RTT}(F)}{|frame|}
$$</p>
<p>Y asumiendo que \(\eta_{proto} = 1\) dado que es óptimo obtenemos que:</p>
<p>$$
SWS = \frac{V_{tx} * \text{RTT}(F)}{|frame|}
$$</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unidad-3---medios-compartidos"><a class="header" href="#unidad-3---medios-compartidos">Unidad 3 - Medios Compartidos</a></h1>
<p>Antes vimos que se podía compartir un canal de transmisión mediante técnicas
como la multiplexación por tiempo o por frecuencia. Esas técnicas lo que
permitían era lograr que varios nodos utilicen el medio "de forma
independiente", o sea que la transmisión de un dispositivo no interfiera con la
de otro.</p>
<p>Ahora vamos a ver otro approach, que es sugerido y generalmente utilizado para
ethernet y en el protocolo de wifi (802.11). La idea es permitir que todos los
dispositivos usen el mismo canal para transferir, y si más adelante hay un
problema (ej 2 quieren transmitir al mismo tiempo) ahí se ve cómo se resuelve.</p>
<p>Y por supuesto se va a buscar minimizar la cantidad de intentos que tiene que
hacer un dispositivo para poder hacer el envio de paquetes deseado y asegurar
fairness.</p>
<p>La tecnología que usa Ethernet y otras redes inalámbricas (802.11), lleva el
nombre de Carrier Sense, Multiple Access with Collision Detect (CSMA/CD). Es un
protocolo que permite que un conjunto de nodos manden mensajes a través de un
enlace compartido.</p>
<ul>
<li>El <strong>Carrier Sense</strong> viene por el hecho de que todos los nodos pueden
distinguir en todo momento si un canal está libre o en uso.</li>
<li>Por otro lado, el <strong>Collision Detect</strong> viene por el hecho de que el emisor a
medida que transmite sensa el canal y puede darse cuenta de si hubo una
colisión en la transmisión con otro nodo.</li>
</ul>
<p>La realidad es que hoy en día la mayoría de las conexiones cableadas son punto
a punto (o sea el enlace es propio de cada par de nodos). Y la parte de
multiplexación la resuelven los switches. Es por eso que hoy en día no está tan
presente el protocolo... redes cableadas.</p>
<p>Por otro lado las redes inalámbricas hoy en día son la norma en muchos entornos
con lo cual el uso de CSMA/CD retoma relevancia.</p>
<p><img src="./img/csma_cd_meme.png" alt="" /></p>
<div id="admonition-dominio-de-colisión" class="admonition admonish-info">
<div class="admonition-title">
<p>Dominio de Colisión</p>
<p><a class="admonition-anchor-link" href="unidad_3.html#admonition-dominio-de-colisión"></a></p>
</div>
<div>
<p>Llamamos <strong>Dominio de Colisión</strong> al conjunto de los nodos que pueden generar
una colisión en el medio al intentar transmitir (no están incluidas los nodos
separados por medio de un switch).</p>
</div>
</div>
<h2 id="csmacd"><a class="header" href="#csmacd">CSMA/CD</a></h2>
<p>Vamos a ver el caso de acceso múltiple en cable ethernet ya que si bien es algo
anecdótico hoy en día, los mismos principios se pueden aplicar a nuevas
tecnologías.</p>
<p>Para empezar hablemos un toque de Ethernet:</p>
<ul>
<li>Admite tramos de hasta 500m (no más para evitar atenuación de la señal).</li>
<li>Admite máximo hasta 4 repetidores</li>
<li>Requiere como mínimo 2,5 metros entre host y host.</li>
<li>Las transmisiones son broadcasteadas a lo largo del cable (y a través de
repetidores)</li>
</ul>
<p>Además, un frame de Ethernet contiene los siguientes campos (segun el estándar 802.3):</p>
<p><img src="./img/eth_frame.png" alt="" /></p>
<ul>
<li>Primero tiene un preámbulo de 64 bits, es una secuencia de 0's y 1's
alternada que le permite al receptor sincronizarse con la señal.</li>
<li>Después le siguen las direcciones de destino y fuente respectivamente que son
direcciones de 48 bits.
<ul>
<li>las direcciones son "únicas" y vienen grabadas en la rom de los
adaptadores de red</li>
<li>El adaptador de red sensa el canal y si ve un frame cuyo campo de
destinatario es su dirección entonces le deriva el frame al host. Hace lo
mismo si el frame tiene la dirección de broadcast.</li>
</ul>
</li>
<li>Después sigue el campo del tipo, que indica a cuál protocolo de más alto
nivel se le enviaría el frame.</li>
<li>Luego el body del frame tiene la data en si a enviar. Un detalle no menor es
que un frame puede contener hasta 1500 bytes de datos, y tiene que tener por
lo menos 46 bytes de datos (esto último es necesario para tener tiempo
suficiente de detectar una colisión) por lo que en caso de no tener
suficientes datos se le agrega algo de padding.</li>
<li>Por último un campo CRC para chequeo de errores</li>
</ul>
<p>Un pequeño detalle es que para el host el frame de ethernet en realidad no
tiene ni el preámbulo ni el CRC, el adaptador de red es el que se encarga de
agregar esos campos extra.</p>
<p>El algoritmo que sigue un transmisor que implementa CSMA/CD se puede resumir con el siguiente diagrama de estados:</p>
<p><img src="./img/csma_cd_state_diagram.png" alt="" /></p>
<ul>
<li>El transmisor siempre que le llega un frame nuevo va a intentar transmitir
<ul>
<li>Si el canal está libre transmite de una</li>
<li>Si el canal está ocupado, espera a que se libere
<ul>
<li>Ni bien se libera, el transmisor va a intentar enviar</li>
</ul>
</li>
</ul>
</li>
<li>Si está transmitiendo, pueden pasar 1 de 2 cosas:
<ul>
<li>Es el único dispositivo usando el canal y el frame se envía correctamente
y sin problemas</li>
<li>Mientras está enviando, otro dispositivo también decide enviar un frame,
generando lo que se conoce como una <strong>colisión</strong>. Para eso el transmisor
sensa el medio y si detecta un voltage anormal entonces eso es a causa de
la colisión
<ul>
<li>Cuando detecta una colisión frena la transmisión actual y envía una
<strong>secuencia de jamming</strong> de 32 bits (por lo general es una tira de
1's y listo). El objetivo de dicha secuencia es hacer que el receptor
deje de escuchar la señal.
<ul>
<li>Eventualmente el otro emisor también va a detectar la colisión y
va a enviar su propia secuencia de jamming.</li>
</ul>
</li>
<li>Una vez que se detecta la colisión y se envía la secuencia de
jamming, se aplica una política de <strong>exponential backoff</strong>. Eso es
esperar un cierto tiempo antes de enviar. Si se vuelve a dar una
colisión, esperar el doble y así hasta que se haga efectiva o se
supere un límite predefinido (en general es de 16 intentos), en cuyo
caso el adaptador avisa al host que la transmisión falló.</li>
</ul>
</li>
</ul>
</li>
</ul>
<div id="admonition-exponential-backoff" class="admonition admonish-info">
<div class="admonition-title">
<p>Exponential Backoff</p>
<p><a class="admonition-anchor-link" href="unidad_3.html#admonition-exponential-backoff"></a></p>
</div>
<div>
<p>Para ser un poco más específico, la idea en el exponential backoff es dividir
el tiempo en slots entre 0 y \(2^k - 1\), siendo \(k\) la cantidad de
intentos. Se elige uno de los slots al azar y eso representa la cantidad de
slots que se espera. Un slot representa 51,2 \(\mu\)s que es el tiempo
necesario para transferir el frame más chico.</p>
</div>
</div>
<p>Ahora que conocemos el algoritmo, tiene más sentido el motivo por el cuál
necesitamos tener al menos 46 bytes de datos a enviar. Esto es porque incluso
en el caso en el que estén los dos hosts lo más alejados posible (2500 metros
usando 4 repetidores), el Round Trip Delay es de al rededor de 51,2 \(\mu\)s
que en una conexión de 10Mbps equivale a 512 bits. De esta forma, si nuestra
frame tiene al menos 512 bits si o si uno de los dos emisores va a detectar la
colisión antes de terminar de enviar su frame.</p>
<div id="admonition-transmisores-p-persistentes" class="admonition admonish-info">
<div class="admonition-title">
<p>Transmisores <em>p</em>-persistentes</p>
<p><a class="admonition-anchor-link" href="unidad_3.html#admonition-transmisores-p-persistentes"></a></p>
</div>
<div>
<p>Ethernet se dice que es un protocolo 1-persistente porque siempre que sensa el
medio y está libre va a intentar enviar. Este es un caso particular de lo que
se conoce como transmisores <em>p</em>-persistentes, en donde se transmite con
probabilidad <em>p</em> una vez que se libera el medio.</p>
</div>
</div>
<p>Una última observación es que en este algoritmo se contempla que sólo se puede
leer <em>o</em> escribir en el canal, pero no los 2 al mismo tiempo. Eso se conoce
como un algoritmo de <strong>half-duplex</strong>. No confundir esto con la clasificación de
canales. El canal puede ser full duplex (se puede escuchar y enviar al mismo
tiempo) mientras que el algoritmo es half duplex.</p>
<p>Recomiendo también pegarle una chusmeada a <a href="https://cs.newpaltz.edu/~easwarac/CCN/Week13/CSMA.pdf">esta explicación</a> de CSMA/CD.</p>
<h3 id="midiendo-performance-de-csma"><a class="header" href="#midiendo-performance-de-csma">Midiendo performance de CSMA</a></h3>
<p>Sean \(S\) la <strong>carga ofrecida</strong> (nro de intentos de transmisión por unidad
de tiempo, o sea cuánto tengo que usar del medio para transmitir) y \(G\) el
<strong>goodput</strong> (proporción de transmisiones exitosas por unidad de tiempo),
entonces:</p>
<p>$$
S = G * (1 - P_{colision})
$$</p>
<p>Podemos graficar la relación entre la carga, el goodput y la variante de CSMA:</p>
<p><img src="./img/link_performance.png#center" alt="" /></p>
<ul>
<li>Aloha es otro protocolo que consiste en lo que vimos antes. Enviar un mensaje
y si no me llega un ACK de dicho mensaje re-enviar. (esto no descarta
totalmente ese mecanismo para asegurar confiabilidad y control de errores
porque como verems más adelante si se usa en protocolos de más alto nivel)
<ul>
<li>Slotted aloha es lo mismo pero la emisión se da en "slots discretos"</li>
</ul>
</li>
<li>CSMA es fácil de implementar pero tiene mala perf en la práctica a medida que
aumenta la carga. (en estudios se validó que a partir de 30% de carga aprox
ya se degrada mucho)</li>
<li>En el gráfico se hace mención de non-persistent CSMA. La diferencia entre
este y 1p-CSMA/CD es que 1p-CSMA/CD transmite ni bien encuentra el canal
libre. En cambio el non persistent sensa el canal y si está en uso espera una
cantidad fija de tiempo (no transmite ni bien se libera). Si bien reduce las
changes de colisión también cae el throughput. Dicho eso reacciona mejor a la
relación entre carga y goodput.</li>
<li>Se hace obvia la relación entre el delay hasta poder transmitir (si espero
más entre cada transmisión) y el goodput, y cómo esto afecta al throughput
final.</li>
</ul>
<hr />
<p>TODO: Resumir diapos 20-24 inclusive (no encuentro referencia en la docu)</p>
<hr />
<h2 id="redes-compartidas-redes-inalámbricas"><a class="header" href="#redes-compartidas-redes-inalámbricas">Redes Compartidas (Redes inalámbricas)</a></h2>
<ul>
<li>En las redes inalámbricas, la señal disminuye / se atenúa con la distancia (mayor impacto que en no inalámbricas)</li>
<li>Además las fuentes de ruido son más impredecibles</li>
<li>Qué sería compartir el medio acá? Se comparte el ancho de banda (el espectro electromagnético).</li>
<li>Está regulado con qué potencia se transmite</li>
<li>El medio es mucho más fácilmente "pinchable" (es por eso que se vuelve una verdadera necesidad encriptar la data)</li>
</ul>
<h3 id="bandas-no-licenciadas"><a class="header" href="#bandas-no-licenciadas">Bandas no licenciadas</a></h3>
<p>Son bandas para las cuales no tengo que pedir permiso para transmitir</p>
<ul>
<li>900 mhz</li>
<li>2.4 ghz</li>
<li>5 ghz</li>
</ul>
<p>Si alguien quiere transmitir en la misma frecuencia me va a generar
interferencia. Entonces surge la pregunta, si 2.4 es una banda no licenciada y
todo el mundo lo usa, cómo es que mi wifi no es interferido por el del vecino?
Eso es el motivo por el cual hay límites a la potencia de la señal.</p>
<p>Además, las bandas se pueden particionar en canales. Por ejemplo, para 2.4 en
wifi tengo la banda partida en 13 canales y sólo puedo usar 3 de esos canales:
el 1, 6 y 7 y cada uno tiene un ancho de 22mhz.</p>
<p>Para el caso de 5ghz, puedo tener canales de 20, 40, 80 y 160 mhz</p>
<p>Más adelante surgió la idea de usar el espectro expandido. La idea es saltar
entre frecuencias varias veces por segundo. Surgió en el contexto de
comunicaciones militares porque hacía más difícil detectar la señal y casi
imposible meterle ruido (el Tanembaum usa el término <a href="https://youtu.be/FcArnepkhv0?si=oO4tNudSObUe5nF5&amp;t=86">jammed</a>).</p>
<h2 id="protocolos-de-acceso-múltiple"><a class="header" href="#protocolos-de-acceso-múltiple">Protocolos de acceso múltiple</a></h2>
<p>Hay 2 problemas importantes que surgen en el uso del medio compartido para wireless:</p>
<ul>
<li>El <strong>problema de la estación oculta</strong>: si tengo la transmisión <code>A -&gt; B     C</code>, <code>C</code> sensa el medio para transmitir y no detecta a <code>A</code> por estar fuera de alcance. Entonces empieza a transmitir, introduciendo ruido en lo que b detecta.</li>
<li>El <strong>problema de la estación expuesta</strong>: si tengo las transmisiones <code>A &lt;- B      C   D</code> y C quiere transmitir a <code>D</code>, puede que <code>C</code> sense el medio y como detecta la transmisión de <code>B</code> a <code>A</code> entonces decide no transmitir cuando en realidad la transmisión de <code>C</code> a <code>D</code> no afectaría la señal que <code>A</code> recibe.</li>
</ul>
<p>Para paliar estos problemas tenemos una variante de CSMA que es <strong>CSMA/CA</strong> (o sea con <strong>collision avoidance</strong>).</p>
<h3 id="csmaca"><a class="header" href="#csmaca">CSMA/CA</a></h3>
<ul>
<li>Antes de transmitir, escucho
<ul>
<li>Si no está ocupado espera un tiempo llamado <strong>espaciado entre tramas
(IFS)</strong></li>
<li>Si está ocupado o se ocupa durante la espera hay que esperar hasta el
final de la transacción
<ul>
<li>Cuando termina la transacción se ejecuta un algoritmo de backoff
<ul>
<li>se espera un valor de una uniforme en un intervalo llamado
<strong>ventana de contención</strong>
<ul>
<li>se mide en slots</li>
<li>si durante ese tiempo el medio está ocupado durante un tiempo
mayor al IFS, se suspende la espera hasta que se cumpla la
condición de canal libre</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>En WiFi se espera recibir ACK a diferencia de ethernet. Si no se recibe se
retransmite a diferencia de ethernet. Si no se recibe se retransmite.</p>
<h2 id="modelo-de-referencia-de-80211-wifi"><a class="header" href="#modelo-de-referencia-de-80211-wifi">Modelo de Referencia de 802.11 (WiFi)</a></h2>
<p>Lo componen 3 subcapas de LLC:</p>
<ul>
<li>A nivel físico:
<ul>
<li>PMD (Physical Media Dependent)
<ul>
<li>Infrarrojos</li>
<li>FHSS</li>
<li>DSSS</li>
<li>OFDM (multiplexación por división de frecuencia ortogonal) + MU-MIMO
(multi-user, multiple input, multiple output)
<ul>
<li>SU-MIMO (Single User) permite al AP comunicarse con un único
dispositivo a la vez. Al dividir el ancho de banda en canales
independientes permite conectarse con varios dispositivos a la
vez.
<img src="./img/mu-mimo.png#center" alt="" /></li>
</ul>
</li>
<li>Hoy ya existe OFDMA que es una variante que usa un único canal para
transmitir todo pero ajusta en base al volumen de tráfico de cada
canal.</li>
</ul>
</li>
<li>PLCP (Physical Layer Convergence Procedure)</li>
</ul>
</li>
<li>A nivel enlace:
<ul>
<li>subcapa MAC:
<ul>
<li>Acceso al medio: CSMA/CA</li>
<li>usa Ack</li>
<li>Fragmentación</li>
<li>Confidencialidad (opcional)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Wifi per se se implementó de forma half duplex (hacerlo full duplex aumentaría costos de fabricación)</p>
<h3 id="ieee-80211-mac"><a class="header" href="#ieee-80211-mac">IEEE 802.11 MAC</a></h3>
<p>Hasta la versión más sencilla de Wifi trabaja con las DCF (Función de
Coordinación distribuída o CSMA-CA). El período de contensión de CSMA-CA desde
el punto de vista estadístico nos da un acceso "equitativo al medio".</p>
<ul>
<li>Se minimiza la colisión entre tramas</li>
<li>Mientras el canal está libre el nodo decrementa el backoff counter
<ul>
<li>si llega a 0 el nodo envía el frame
<ul>
<li>si no recibe ack (o sea asume que hubo un error/colisión en la transmisión), se elige una nueva ventana de contensión en un rango del doble del anterior.</li>
<li>se repite hasta que el canal esté libre para enviar</li>
</ul>
</li>
</ul>
</li>
</ul>
<div id="admonition-evolución-wifi" class="admonition admonish-info">
<div class="admonition-title">
<p>Evolución WiFi</p>
<p><a class="admonition-anchor-link" href="unidad_3.html#admonition-evolución-wifi"></a></p>
</div>
<div>
<p>En la siguiente tabla se puede ver la evolución del protocolo a lo largo del
tiempo:</p>
<p><img src="./img/wifi_evolution.png#center" alt="" /></p>
<p>Ojo, la velocidad es en bps (a nivel físico). Una estimación grosera es por
ejemplo para 802.11n de los 600Mbps, <strong>en tu lan</strong> vas a alcanzar unos 300Mbps.
El resto se lo llevan los headers del mismo protocolo entre otras cosas.</p>
</div>
</div>
<div id="admonition-ejercicio-de-final---análisis-de-performance" class="admonition admonish-warning">
<div class="admonition-title">
<p>Ejercicio de final - Análisis de Performance</p>
<p><a class="admonition-anchor-link" href="unidad_3.html#admonition-ejercicio-de-final---análisis-de-performance"></a></p>
</div>
<div>
<ul>
<li>Tenemos una notebook que accede al servicio de banda ancha ADSL mediante un <strong>AP 802.11ac</strong>.</li>
<li>El AP se conecta al Home Gateway</li>
<li>El servicio ADSL tiene una velocidad de transmisión máxima de 1Gbps</li>
<li>Queremos hacer una transferencia de un archivo de 10GB desde un servidor en USA a la notebook.</li>
</ul>
<p>Cuánto estimamos que demora la transferencia?</p>
<ol>
<li>Si hacen 10GB * 8 / 1Gbps... hay tabla. Hay que chequear más cosas.</li>
</ol>
<ul>
<li>Un dato importante es que la notebook se conecta mediante un AP 802.11ac!</li>
<li>La velocidad del servicio de banda ancha, a qué nivel está medido? (vamos a
suponer que está medido a nivel IP)</li>
<li>cuál es la velocidad de bajada y cuál es la de subida? (en gral la de subida
es aprox. 1 a 20 veces la de bajada).
<ul>
<li>si es un 802.11n ya tengo a nivel enlace un cuello de botella de 390Mbps</li>
<li>si es un 802.11ac Wave 1 también es cuello de botella</li>
<li>También depende de qué soporte la notebook.</li>
<li>En el oral si no está especificado habría que preguntar</li>
<li>Hay que ver el RTT del servidor también</li>
</ul>
</li>
<li>otra cosa que puede pasar es que haya atenuación y obstáculos en el medio, y
en esos casos el ap baja de 1024 QAM por ejemplo a un esquema de modulación
más bajo, y por entre transmite a una velocidad más baja.</li>
</ul>
</div>
</div>
<h3 id="anomalía-del-wifi"><a class="header" href="#anomalía-del-wifi">Anomalía del Wifi</a></h3>
<ul>
<li>WiFi da acceso equitativo al medio.</li>
<li>Los nodos de más baja velocidad consumen más "tiempo de aire", y además al
ser más rápidos los nodos más rápidos reciben menos tiempo de aire.</li>
<li>en consecuencia los nodos con velocidad baja degradan la velocidad de los
nodos de mayor velocidad.</li>
</ul>
<h2 id="data-link-layer-switching"><a class="header" href="#data-link-layer-switching">Data Link Layer Switching</a></h2>
<p>Una <strong>LAN</strong> (Local Area Network) es una red privada que opera de forma cerrada.
Vimos además que en la infraestructura de red tenemos algo que nos conecta a la
red interna del proveedor de internet (DSLAM por ejemplo). Ahora, qué pasa
cuando tengo varias LANs y las quiero unir para que se comporten como una única
LAN.</p>
<p>Esto se puede lograr con dispositivos llamados <strong>bridges</strong>, hoy también
llamados switches. Notar que por ahora nos vamos a referir a los switches como
dispositivos de capa de enlace pero también hay switches que operan en la capa
de red. Al operar en capa de enlace, sólo les interesa forwardear los frames en
base a la dirección de destino. Cualquier protocolo montado sobre la capa de
enlace (sea IP, AppleTalk, u otros) van a ser soportados por un bridge, a
diferencia de lo que ocurre con los switches de la capa de red que sólo
soportan los protocolos para los que se los programó.</p>
<p>Algunos casos de uso:</p>
<ul>
<li>En la facu cada departamento tiene su propia LAN, pero además queremos tener
una única red para todos los dispositivos de la facultad</li>
<li>A veces queremos partir una LAN en muchas para distribuir la carga (si no
floodeariamos toda la red por cada comunicación)
<ul>
<li>Esto también lograría particionar el dominio de colisión</li>
<li>cómo logramos esto? Bueno, los bridges sólo forwardean frames por los
puertos que haga falta.</li>
</ul>
</li>
</ul>
<div id="admonition-supongamos" class="admonition admonish-info">
<div class="admonition-title">
<p>Supongamos...</p>
<p><a class="admonition-anchor-link" href="unidad_3.html#admonition-supongamos"></a></p>
</div>
<div>
<p>Veamos lo que pasa bajo las siguientes 3 siguaciones:</p>
<p><img src="./img/network_topologies.png" alt="" /></p>
<ul>
<li>En a) tengo todos los hosts conectados a un mismo hub, por lo que todos
comparten el mismo medio físico y puede haber colisiones (y tenemos que
pensar en modelos de ack o un CSMA/CA)</li>
<li>En b) Tengo la LAN separada en 2 de cada lado hay un dominio de colisión y
por ende todavía pueden haber colisiones.</li>
<li>En c) están todos los hosts conectados a un switch, por ende ahora la
cuestión pasa por el mismo, que guarda en sus buffers los frames y va
despachando. En este caso directamente desaparecen las potenciales
colisiones, ACK, CSMA/CD y pasa a ser un problema algorítmico de cómo el
switch maneja esos buffers y los dispatch.</li>
</ul>
</div>
</div>
<p>Notar que para que estas cosas sean posibles, es necesario que funcionen de la
forma más transparente posible y sin mucha configuración adicional. Y los
dispositivos dentro de una LAN no deberían de enterarse que forman parte de una
LAN más grande a priori. Se usan dos algoritmos para bridges que nos proveen
dicha transparencia:</p>
<ul>
<li>Primero un algoritmo para "aprender" dónde no hace falta forwardear frames (o
sea evitar generar tráfico innecesario).</li>
<li>Y además un algoritmo (de AGM) que nos permite romper los ciclos dentro de la
red (para que no queden frames zombies dando vueltas).</li>
</ul>
<h3 id="cómo-operan-los-bridges--switches"><a class="header" href="#cómo-operan-los-bridges--switches">Cómo operan los bridges / switches</a></h3>
<p>Los bridges operan en modo promiscuo, lo que significa que acepta todos los
frames que llegan en cada uno de sus puertos y decide si forwardea o descarta
el frame y en caso de forwardearlo por cuál puerto. Para decidir eso último se
basa en la dirección de destino de la metadata del frame.</p>
<p>Una forma de implementar esto podría ser con una tabla de hash que mapea
<code>dirección destino -&gt; puerto de salida</code>. Sin embargo la tabla inicia vacía, por
lo que se procede a usar un algoritmo de flooding. Cada frame que vaya a un
host que todavía no conocemos se forwardea al resto de los puertos, y una vez
que se conoce se deja de forwardear y se manda por el puerto correspondiente. Y
cómo me entero de qué puerto le corresponde a una dirección? Bueno, puedo ver
la dirección del host que envía el frame.</p>
<p>La topología de la red puede cambiar. Para manejar esos casos, lo que hacemos
es guardarnos la asociación <code>addr -&gt; (port, timestamp)</code>. Cada vez que recibo un
frame y el host src está en la tabla de hash, actualizo el timestamp, y
periódicamente se limpian las entradas de la tabla que tengan más de un par de
minutos.</p>
<p>El algoritmo entonces se puede resumir a:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if not table.contains(frame.dstAddr) { forward_except_port(frame, frame.srcPort) } // Descarto el frame (srcPort en realidad no es parte del frame, es una simplificación)
else if frame.srcPort == table[frame.dstAddr] {  } // Descarto el frame
else { send(frame, table[frame.dstAddr]) } // Lo mando por el puerto que corresponde
<span class="boring">}</span></code></pre></pre>
<h4 id="spanning-tree-bridges"><a class="header" href="#spanning-tree-bridges">Spanning Tree Bridges</a></h4>
<p>Para mejorar la disponibilidad y tolerancia a fallos, es normal que hayan
enlaces redundantes, cosa de que si uno falla no se fragmente la red. Sin
embargo, este tipo de situaciones trae algunos problemas ya que introducimos
ciclos en la topología de la red.</p>
<p>Por qué los ciclos son un problema? Porque si recordamos el algoritmo hace que
forwardiemos frames cuyos destinatorios no conocemos. Entonces el frame se
mueve permanentemente a lo largo del ciclo. Para solucionar esto, se establece
un protocolo para los mismos bridges que les permite mantener una idea de AGM
de la red. Y sí, nos vamos a olvidar de algunos enlaces para lograr esta
estructura acíclica.</p>
<p>Para construir dicho Árbol Generador Mínimo, los bridges corren un algoritmo
distribuido. El mismo consiste en:</p>
<ul>
<li>Cada bridge periódicamente broadcastea un mensaje de configuración a todos
sus puertos</li>
<li>También procesa los mensajes de configuración que reciben de sus vecinos.
Estos mensajes no son forwardeados ya que no queremos caer en el problema de
loops nuevamente.</li>
<li>El primer paso es ponerse de acuerdo en qué nodo va a ser la raiz del AGM.
Para eso incluyen en sus mensajes de configuración su MAC address junto al
identificador del bridge que creen que es la raíz.
<ul>
<li>Eligen como raíz al de identificador más chico</li>
</ul>
</li>
<li>Una vez elegida la raíz, se construye un arbol de caminos mínimos desde la
misma hasta cada otro bridge. Las distancias son la cantidad de saltos que se
requieren para llegar de un nodo a otro. Los casos de empate se resuelven
mirando el identificador.
<ul>
<li>Para encontrar los caminos mínimos, los bridges mantienen el camino
mínimo que tienen hasta la raíz. Y "apagan" los puertos que no forman
parte de ese camino (notar que el camino de cada puerto puede ser
independiente de los otros).</li>
</ul>
</li>
<li>Una vez que el AGM se estabiliza, los bridges vuelven al modo de operación
usual. Sin embargo el algoritmo se corre cada tanto para detectar cambios en
la topología de la red y actualizar el árbol.</li>
</ul>
<h3 id="vlans"><a class="header" href="#vlans">VLANs</a></h3>
<p>Las VLANs surgen como consecuencia de la necesidad de desacoplar la conexión
física de una posible conexión lógica (diferentes áreas en una empresa, por
ejemplo) y brindar mayor flexibilidad en el manejo de la red.</p>
<p>Usan Switches especiales que están al tanto de la existencia de las VLANs.</p>
<ul>
<li>Requieren que los bridges tengan una configuración de qué VLANs son
accedibles por qué puerto.
<ul>
<li>Dicha marca sirve como filtro en todo el algoritmo del bridge. O sea sólo
forwardea y broadcastea por los puertos correspondientes a la vlan del
frame recibido.</li>
</ul>
</li>
</ul>
<p>Para soportar esto se agregó a partir del estándar <strong>802.1Q</strong> un tag de VLAN al
header del frame ethernet. Una de las claves para llevar esto a la práctica es
que a priori los hosts no se enteran de la existencia de las VLANs, por lo que
puede ser info que se agrega una vez sale del host. De hecho el primer bridge
que sea VLAN-aware es el que agrega el campo y el último bridge lo saca.</p>
<ul>
<li>Todos los hosts de un puerto tienen que pertenecer a la misma VLAN</li>
<li>El único cambio al header es el agregado de 2 bytes:
<ul>
<li>VLAN protocol ID (constante = <code>0x8100</code>)</li>
<li>Un byte compuesto por 3 fieldss:
<ul>
<li>un bit de prioridad (no relacionado a VLAN pero lo agregaron porque
no pasa seguido que se cambia el protocolo). Sirve para identificar
tráfico con requisito de real-time vs soft real-time.</li>
<li>un bit de CFI (canonical format indicator), servía para marcar si era
big endian / little endian pero después se cambió (sth sth politics
sth).</li>
<li>un VLAN Identifier de 12 bits (o sea el "color" de la VLAN al que
pertenece el frame)</li>
</ul>
</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unidad-4---nivel-de-red"><a class="header" href="#unidad-4---nivel-de-red">Unidad 4 - Nivel de Red</a></h1>
<p><img src="./img/osi_isp.png#center" alt="" /></p>
<p>Retomando el modelo OSI, podemos ver que de capa 3 para abajo tenemos lo que se
llama el <strong>límite de subred de comunicación</strong>, que delimita las capas sobre las
que operan los isp.</p>
<h2 id="redes-escalables-con-switches"><a class="header" href="#redes-escalables-con-switches">Redes escalables... con switches</a></h2>
<p>Peterson afirma que internet es una red <strong>escalable</strong>. Por escalable vamos a
entender como aquello que cuando crece, el costo de su
mantenimiento/administración es mínimo. Internet no solo es escalable, es
<strong>altamente escalable</strong>.</p>
<p>Cómo se logra eso? Principalmente mediante <strong>routers/switches</strong>. Su objetivo
principal es conmutar o forwardear paquetes. Dependiendo el tipo de switch, van
a distribuir paquetes mediante:</p>
<ul>
<li><strong>circuitos virtuales</strong></li>
<li><strong>conmutación de datagramas</strong></li>
</ul>
<p>Notar que ambos pertenecen al paradigma de conmutación de paquetes, pero
también existe lo que antes se usaba que era la conmutación de circuitos.</p>
<h3 id="conmutación-de-paquetes"><a class="header" href="#conmutación-de-paquetes">Conmutación de paquetes</a></h3>
<p>Tenemos 2 paradigmas (que usan una u otra forma de distribuir paquetes):</p>
<ul>
<li>Orientado a conexión (circuitos virtuales): acá también mando varios
paquetes, pero el camino es fijo. <img src="./img/virtual_circuits.png" alt="" />
<ul>
<li>necesito "alguna magia" que arme toda la ruta</li>
<li>le decimos "orientado a conexión" porque previamente establezco una
comunicación entre ambos hosts.</li>
<li>tengo 3 fases:
<ul>
<li>establecer conexión</li>
<li>mandar datos</li>
<li>levantar la conexión</li>
</ul>
</li>
<li>llegan en orden</li>
</ul>
</li>
<li>Sin conexión (datagramas IP): parto la info a mandar en datagramas (cachitos
de info) y la mando, cada uno puede tomar una ruta a destino distinta y
podrían llegar desordenados. <img src="./img/datagrams.png" alt="" />
<ul>
<li><strong>no existe una fase para establecer una conexión</strong></li>
<li>como cada paquete se envía de forma independiente, tiene que ser
autosuficiente. O sea necesita dir fuente y dir destino (cof cof IP)</li>
</ul>
</li>
</ul>
<p>Si bien circuitos virtuales estaba medio muerto, con la tecnología 5G tuvo un
renacimiento, aunque se lo llama <strong>slicing</strong></p>
<h4 id="conmutación-sin-conexión"><a class="header" href="#conmutación-sin-conexión">Conmutación sin conexión</a></h4>
<ul>
<li>cada switch mantiene una tabla de forwarding
<ul>
<li>uso un <strong>algoritmo de ruteo</strong> para armarla</li>
</ul>
</li>
<li>la tabla me dice a dónde mandar un paquete en base a la dirección destino.</li>
<li>tuvo que haber un algoritmo de seteo inicial para armar esas tablas</li>
</ul>
<p><img src="./img/datagram_routing_scheme.png" alt="" /></p>
<h4 id="conmutación-orientada-a-conexión--circuitos-virtuales"><a class="header" href="#conmutación-orientada-a-conexión--circuitos-virtuales">Conmutación orientada a conexión / Circuitos virtuales</a></h4>
<ul>
<li>al igual que datagramas se arma una tabla pero una <strong>tabla de circuitos
virtuales</strong> (no vamos a estudiar cómo). La misma tiene:
<ul>
<li>Puerto por donde llega un paquete</li>
<li>VCI (id del circuito) de entrada</li>
<li>puerto de salida del paquete</li>
<li>id del VCI de salida</li>
</ul>
</li>
<li>cómo armo la tabla de circuitos? cómo armo los VCI?</li>
<li>cómo sé dónde está cada nodo?</li>
<li>Tengo 2 tipos:
<ul>
<li>permanente (la define el administrador)
<ul>
<li>se tiene que configurar y recién ahí puedo proceder a mandar datos</li>
</ul>
</li>
<li>por solicitud o conmutado
<ul>
<li>se mandan mensajes de solicitud de conexión a la red</li>
<li>se arma una cadena de switches que llevan hasta el host destino que
tienen que aceptar la conexión y propagar la solicitud al siguiente
switch / nodo.</li>
<li>una vez construido el circuito virtual se empiezan a enviar datos</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Cuál sería algún incentivo para preferir circuitos virtuales? Al establecer la
conexión uno puede "reservar" recursos (léase ancho de banda, buffers, etc.)
puedo garantizar cierta calidad de servicio y mejor control de congestión.</p>
<h4 id="modelo-de-datagrama-vs-circuitos"><a class="header" href="#modelo-de-datagrama-vs-circuitos">Modelo de Datagrama vs Circuitos</a></h4>
<p>Datagrama:</p>
<ul>
<li>No hace falta esperar a un RTT para establecer una conexión</li>
<li>Inmediatamente disponible para mandar datos</li>
<li>Envío paquete sin establecer conexión</li>
<li>Estadísticamente los datagramas llegan en orden</li>
<li>Hago mi mejor esfuerzo para rutear el paquete en la red</li>
</ul>
<p>Circuitos Virtuales:</p>
<ul>
<li>Necesito fase inicial para establecer una conexión y una final para
liberarla, que no transportan datos del usuario
<ul>
<li>tengo algo de overhead</li>
</ul>
</li>
<li>Una vez establecido el circuito se usa siempre eso para mandar (no es adaptable a fallas/congestión)</li>
</ul>
<p>Ahora, una vez establecida la conexión los circuitos virtuales funcionan mucho
mejor. Por qué entonces ganó datagramas.</p>
<ul>
<li>Circuitos virtuales requería más infraestructura del lado del ISP
<ul>
<li>Eso también permitía ser más exigentes con el costo del servicio (ej: te
cobro por cada paquete transmitido)</li>
<li>Al ser más complejo es también menos escalable</li>
</ul>
</li>
<li>Si bien con datagramas la comunicación es "boba", eventualmente se armaron
protocolos que permiten resolver algunos de los problemas que circuitos
virtuales resolvía mediante infra, pero con software (esa solución es la que
conocemos como TCP).</li>
</ul>
<div id="admonition-conmutación-de-circuitos-vs-conmutación-de-paquetes" class="admonition admonish-warning">
<div class="admonition-title">
<p>Conmutación de circuitos vs. Conmutación de paquetes</p>
<p><a class="admonition-anchor-link" href="unidad_4.html#admonition-conmutación-de-circuitos-vs-conmutación-de-paquetes"></a></p>
</div>
<div>
<p>Algo en lo que se hizo mucho incapié es en el hecho de que podemos llegar a
confundir circuitos virtuales con conmutación de circuitos, y que por ende
ambos operan en capas 1, 2 y 3. Sin embargo, recordemos que conmutación de
circuitos refiere a lo visto para la unidad 0 y aplica únicamente a capa 1
(física).</p>
</div>
</div>
<h3 id="ip-en-internet"><a class="header" href="#ip-en-internet">IP en Internet</a></h3>
<ul>
<li>Permito interconexión de redes</li>
<li>A priori puedo tener distintos tipos de conexiones a lo largo del camino que
toma el paquete, pero el "glue code" viene a ser ip: <img src="./img/ip_stack.png" alt="" /></li>
<li>IP <strong>ES SENCILLO</strong>
<ul>
<li>El formato fundamentalmente es agregar dos campos, hay más cosas pero el
core son los campos de dirección fuente y destino</li>
</ul>
</li>
</ul>
<h3 id="campos-del-header-ip-versión-4"><a class="header" href="#campos-del-header-ip-versión-4">Campos del header IP (versión 4)</a></h3>
<ul>
<li>Header de 20bytes con 40 bytes extra para campos opcionales</li>
<li>Los campos
<ul>
<li><em>Versión</em>: para tener versiones coexistiendo</li>
<li><em>Longitud del header</em>: ya que puede crecer por los opcionales</li>
<li><em>DiffServ/ECN</em>: permite dar prioridad a cierto tráfico (ej: puedo
configurar los routers de mi red para que prioricen al ECN específico)</li>
<li><em>Longitud total</em>: en bytes e incluyendo el header</li>
<li><em>Fragmentación</em>: Ta compuesto por varios sub-campos: Identificación, bit
de No fragmentar (DF), bit de más fragmentar (MF) y un bit de
desplazamiento.
<ul>
<li>No todas las tecnologías de acceso al medio tiene el mismo tamaño de
trama. Entonces IP necesita un mecanismo de fragmentación para pasar
por distintos tipos de redes con distintas tecnologías de acceso al
medio.</li>
</ul>
</li>
<li><em>TTL</em>: es un contador que se decrementa con cada salto entre routers. Si
llega a 0 se descarta el paquete.</li>
<li><em>Checksum</em>: sólo del header, no de los datos (TCP es el único que hace
correción de errores)</li>
<li><em>Dirección fuente y destino</em>: de 32 bits</li>
<li><em>Protocolo</em>: un identificador que le permite al router saber qué lleva el paquete IP
<img src="./img/ip_protocol_field.png" alt="" /></li>
</ul>
</li>
</ul>
<h4 id="fragmentación-y-re-ensamblado"><a class="header" href="#fragmentación-y-re-ensamblado">Fragmentación y re-ensamblado</a></h4>
<ul>
<li>Cada tecnología de acceso al medio tiene (a nivel de enlace), un <strong>MTU</strong>
(Maximum Transmission Unit)
<ul>
<li>ej: en Ethernet son 1500 bytes, en FDDI 4500 bytes</li>
</ul>
</li>
<li>Entonces, IP se adapta a la tecnología de enlace
<ul>
<li>Si recibo un datagrama y MTU &lt; |Datagrama|, lo tengo que partir en
fragmentos o <strong>fragmentar</strong> y el host destino los <strong>reensabla</strong></li>
<li>Los fragmentos llevan un identificador cosa de saber cuáles corresponden
a un mismo datagrama</li>
<li>Además contienen:
<ul>
<li>un offset para poder ordenarlos</li>
<li>un bit para marcar el último fragmento</li>
</ul>
</li>
</ul>
</li>
<li>Hoy en día, estadísticamente, la fragmentación es mínima (si tenés mucha
fragmentación puede que te estén hackeando).</li>
</ul>
<h3 id="direccionamiento-global"><a class="header" href="#direccionamiento-global">Direccionamiento Global</a></h3>
<ul>
<li>Se pensó una organización <strong>jerárquica</strong>
<ul>
<li>Una dirección compuesta por red + host</li>
</ul>
</li>
<li>Las direcciones son "globalmente únicas"</li>
<li>Esquema de clases <em>A</em>, <em>B</em> y <em>C</em>
<ul>
<li>las clases más altas pueden tener más hosts</li>
</ul>
</li>
</ul>
<h3 id="forwarding-de-ip"><a class="header" href="#forwarding-de-ip">Forwarding de IP</a></h3>
<p>Cómo hacen los routers para saber a dónde mandar un datagrama?</p>
<ul>
<li>El datagrama recordemos tiene la dirección destino</li>
<li>Si el router está en dicha dirección destino, entonces hace el forward al
host</li>
<li>Si no está conectado directamente a esa red, tiene que hacer un forward a
otro router que lo elige en base a su <strong>tabla de forwarding</strong>
<ul>
<li>mapea una dirección de red al <em>next hop</em></li>
</ul>
</li>
<li>Además cada host tiene un default router</li>
</ul>
<h3 id="ipv6"><a class="header" href="#ipv6">IPV6</a></h3>
<ul>
<li>Se definió en la década del 90'.</li>
<li>El número de dispositivos totales que soportaba IPv4 admitía ~4300 millones de direcciones.</li>
<li>En su momento no se pensaba que ibamos a quedarnos sin direcciones pero hoy en día ya es una realidad.</li>
<li>Usa 128 bits de direccionamiento en lugar de sólo 32 bits</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unidad-5---ruteo"><a class="header" href="#unidad-5---ruteo">Unidad 5 - Ruteo</a></h1>
<h2 id="internetworking"><a class="header" href="#internetworking">Internetworking</a></h2>
<p>En el 74' publican un paper de lo que se iba a a convertir en el protocolo
TCP/IP. Sin embargo, a este le faltaba una parte fundamental de lo que es hoy
en día que es el <strong>ruteo</strong>.</p>
<h3 id="sistemas-autónomos"><a class="header" href="#sistemas-autónomos">Sistemas autónomos</a></h3>
<p>Uno podría decir que internet es la interconexión entre <strong>sistemas autónomos</strong>, que
los definimos como un conjunto de routers administrados por la misma entidad.
Por ejemplo, la red de algún ministerio, la de la facultad, la de tu trabajo,
etc.</p>
<ul>
<li>Tengo 2 tipos de ruteo:
<ul>
<li>interno(IGP): lo que se mueve dentro del sistema autónomo</li>
<li>externo(EGP): lo que va hacia otro sistema autónomo
<ul>
<li>hoy en día el protocolo estandarizado para esto es <strong>BGP</strong> (Border
Gateway Protocol)</li>
</ul>
</li>
</ul>
</li>
<li>A priori lo que pasa adentro de un sistema autónomo queda dentro del sistema
autónomo. Los otros sistemas autónomos no conocen esos detalles.
<ul>
<li>Dicho eso, hay 2 protocolos dentro de los más usados
<ul>
<li><strong>RIP</strong></li>
<li><strong>OSPF</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Nosotros vamos a priorizar protocolos de ruteo interno. De ruteo externo más
que nada hablamos de las políticas.</p>
<div id="admonition-analizando-la-red" class="admonition admonish-info">
<div class="admonition-title">
<p>Analizando la red</p>
<p><a class="admonition-anchor-link" href="unidad_5.html#admonition-analizando-la-red"></a></p>
</div>
<div>
<p>Si pensamos en la internet como la interconexión de sistemas autónomos, podemos también querer analizar el grafo subyacente de esas interconexiones. Pero esa no es la única forma de analizarlo. Podemos armar:</p>
<ul>
<li>grafo de routers</li>
<li>grafo de Web servers</li>
<li>grafo de Name servers</li>
<li>grafo P2P</li>
<li>grafo CDN</li>
<li>etc.</li>
</ul>
</div>
</div>
<h3 id="ruteo"><a class="header" href="#ruteo">Ruteo</a></h3>
<p>En última instancia, nuestro problema se reduce a poder mandar los
paquetes/frames de una punta a la otra. Tenemos 2 procesos:</p>
<ul>
<li>Forwarding (esto es similar a lo que vimos con los learning bridges) consiste
en <strong>elegir una puerta de salida</strong> mirando la dirección destino y tablas de
ruteo.</li>
<li>Ruteo: este es el proceso por el que <strong>construimos las tablas de ruteo</strong>
<ul>
<li>Es un problema de grafos</li>
<li>Vemos a la red como un conjunto de nodos y arcos pesados</li>
</ul>
</li>
</ul>
<p>Además hay 2 tipos de ruteo:</p>
<ul>
<li>Estático: lo configuro una vez y listo</li>
<li>Dinámico: se configura autónomamente y se adapta a cambios en la topología de
la red.</li>
</ul>
<div id="admonition-ruteo-en-modelo-osi" class="admonition admonish-info">
<div class="admonition-title">
<p>Ruteo en modelo OSI</p>
<p><a class="admonition-anchor-link" href="unidad_5.html#admonition-ruteo-en-modelo-osi"></a></p>
</div>
<div>
<ul>
<li>Llamamos <strong>PDU</strong> (Protocol Data Unit)
<ul>
<li>A nivel 4 es un segmento</li>
<li>A nivel 3 es un datagrama</li>
<li>A nivel 2 es un frame</li>
<li>el PDU es la unidad de datos relevante para cada capa. Esto contiene no
sólo la data que viene de la capa superior/inferior, si no también el
encapsulado hecho por la capa</li>
</ul>
</li>
<li>Al nivel 3 lo conforman un par de protocolos:
<ul>
<li>Protocolos de ruteo
<ul>
<li>permite elegir caminos para los datagramas</li>
</ul>
</li>
<li>Protocolo de IP
<ul>
<li>describe las convenciones de direccionamiento, el formato de los
datagramas y las convenciones sobre el manejo de paquetes</li>
</ul>
</li>
<li>Protocolo ICMP
<ul>
<li>permite reporte de errores, mandar señales entre routers entre otras
cosas</li>
<li>por ejemplo, las aplicacioneas <em>ping</em> y <em>traceroute</em> están basadas en
el envío de paquetes ICMP. Ping manda un mensaje de <em>ICMP echo
request</em> y cuando le llega al destino responde. Se repite varias
veces y se sacan métricas. Traceroute arranca con TLL = 0 y envía el
echo request y va aumentando el TTL de a 1, entonces cada request va
encontrando un hop nuevo cada vez.</li>
<li><a href="https://www.cloudflare.com/en-gb/learning/ddos/glossary/internet-control-message-protocol-icmp/">offtopic</a>:
explicación breve de cloudfare sobre qué es el protocolo ICMP y
algunos ataques conocidos <img src="./img/traceroute.gif#center" alt="" /></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="./img/routing_osi.png" alt="" /></p>
</div>
</div>
<h3 id="tablas-de-ruteo-y-de-forwarding"><a class="header" href="#tablas-de-ruteo-y-de-forwarding">Tablas de Ruteo y de forwarding</a></h3>
<ul>
<li>La tabla de enrutamiento dice a qué "next hop" mandar el paquete (tiene la
info lógica)
<ul>
<li>además como next hop puedo tener un default gateway (por ejemplo, en gral
el router de nuestra casa sigue la regla de que todo lo que no esté
dentro de la red sale al default gateway)</li>
<li>si el dstAddr pertenece a la misma red que el router entonces ya puede
mandar el paquete por la interface correspondiente a esa red.</li>
</ul>
</li>
<li>La tabla de forwarding dice cómo mandar el paquete a un next hop (tiene la
info física)
<ul>
<li>cómo se le asigna inicialmente una ip si recién me conecto? DHCP (lo
vemos más adelante), que te provee de una IP privada para la red local.</li>
</ul>
</li>
<li>el mapeo de dirección IP -&gt; dirección física se conoce mediante ARP
(Adress Resolution Protocol)</li>
</ul>
<h4 id="arp"><a class="header" href="#arp">ARP</a></h4>
<p><img src="./img/routing_forwarding_tables.png" alt="" /></p>
<ul>
<li>Cada router mantiene una tabla (ARP table o ARP cache)
que mappea addrIP -&gt; addrFísica</li>
<li>Aprox. cada 15 minutos se reinicia dicha tabla</li>
<li>Algoritmo: si al momento de mandar no tiene el mapeo
IP -&gt; MAC entonces broadcastea un ARP query. La query
tiene la dirección IP. El host que recibe la query y
matchea su dirección ip con la de la query, manda una
respuesta que contiene la MAC.</li>
<li>También en el ARP query se incluye la dirección del
que emite la request lo cual hace que todos los otros
hosts y routers que lo reciban ya conozcan la
dirección física que le corresponde a la IP que hizo
la query.</li>
<li>Al igual que pasaba con las tablas de los learning
bridges, si ya estaba en la tabla se resetea el tiempo
límite para sacar la row de dicha tabla.</li>
</ul>
<h4 id="dhcp"><a class="header" href="#dhcp">DHCP</a></h4>
<ul>
<li>Es un método de configuración dinámica para asignar IPs a los distintos nodos
de una red.</li>
<li>El detalle principal es la existencia de al menos un servidor DHCP.
<ul>
<li>el servidor mantiene una pool de direcciones disponibles que va a ir
administrando de forma automática.</li>
</ul>
</li>
<li>Además, dado que la idea es minimizar la cantidad de configuración a realizar
también se provee un mecanismo para que los hosts encuentren y se puedan
comunicar con el servidor DHCP.
<ul>
<li>Envían un mensaje <em>DHCPDISCOVER</em> a la dirección de ip de broadcast</li>
<li>El servidor DHCP eventualmente recibe el paquete y responde</li>
</ul>
</li>
<li>Además, no siempre contamos con un servidor DHCP por red (ni siempre es
deseable), por lo que también se cuenta con <em>relay agents</em> que su función es
mantener la dirección IP del servidor DHCP. El relay agent se encarga de
mandarle al servidor DHCP los mensajes <em>DHCPDISCOVER</em> que recibe.</li>
<li>El protocolo también admite la posibilidad de que la ip se otorgue por un
tiempo determinado. Esto permite olvidarnos de detectar nodos caídos o que se
desconectan y facilitan el manejo y la liberación de recursos para el
servidor.
<ul>
<li>Los hosts tienen la posibilidad de "renovar" dichas direcciones IP</li>
</ul>
</li>
</ul>
<h3 id="algoritmos-de-ruteo-interno"><a class="header" href="#algoritmos-de-ruteo-interno">Algoritmos de ruteo interno</a></h3>
<p>Se clasifican en:</p>
<ul>
<li><strong>Distance vector</strong></li>
<li><strong>Link state</strong></li>
</ul>
<p>Y estos dan lugar a los protocolos de ruteo (RIP y OSPF)</p>
<div class="table-wrapper"><table><thead><tr><th>Cada Router</th><th>DISTANCE-VECTOR</th><th>LINK-STATE</th></tr></thead><tbody>
<tr><td>Qué informa?</td><td>Toda su tabla de ruteo</td><td>Sólo el estado de sus enlaces directos</td></tr>
<tr><td>A quién le pasa la info?</td><td>Sólo a sus vecinos</td><td>A toda la red (hace flooding)</td></tr>
<tr><td>Algoritmo utilizado</td><td>Bellman-Ford distribuido</td><td>Dijkstra</td></tr>
<tr><td>Datos utilizados</td><td>Info de sus vecinos</td><td>Estado de enlaces de cada nodo</td></tr>
<tr><td>Estructuras de datos</td><td>Tabla de distancias y Tabla de ruteo</td><td>Tabla de Estado de Enlaces y tabla de ruteo</td></tr>
<tr><td>Características</td><td>Ciclos de Ruteo</td><td>Visión consistente de la red</td></tr>
<tr><td></td><td>Gran variedad de algoritmos(Merlin-Segall, Jaffe-Moss, entre otros.)</td><td>Algoritmo básico único</td></tr>
<tr><td></td><td>Cálculo distribuido</td><td>Cálculo centralizado</td></tr>
<tr><td></td><td></td><td>Mucho uso de CPU y Memoria</td></tr>
<tr><td>Protocolo de Internet</td><td>RIP</td><td>OSPF</td></tr>
</tbody></table>
</div><div id="admonition-pequeño-recuerdo-de-bellman-ford-vs-dijstra" class="admonition admonish-info">
<div class="admonition-title">
<p>Pequeño recuerdo de Bellman-Ford vs Dijstra</p>
<p><a class="admonition-anchor-link" href="unidad_5.html#admonition-pequeño-recuerdo-de-bellman-ford-vs-dijstra"></a></p>
</div>
<div>
<p>Ambos algoritmos permiten construir un arbol de caminos mínimos con raíz en un
nodo <em>v</em></p>
<h4 id="bellman-ford"><a class="header" href="#bellman-ford">Bellman-Ford</a></h4>
<p>Idea: construyo un arbol de caminos mínimos parcial \(T_k\) donde
\(T_k[i]\) te dice la distancia del camino mínimo del nodo \(i\) a la raiz
\(v\) usando a lo sumo \(k-1\) ejes, y cuál es su antecesor en ese camino.
Eventualmente el \(T_{|V|-1}\) tiene lo que quiero.</p>
<h4 id="dijkstra"><a class="header" href="#dijkstra">Dijkstra</a></h4>
<p>Idea: es el algoritmo de prim de AGM pero cambiamos la función que se usa para
definir qué nodo agregar y con qué arista. Elijo aquél nodo cuya distancia a la
raíz se minimice con la arista agregada. O sea si tengo el subárbol generador
\(T_k\) enraizado en \(v\), agregamos el nodo \(w\) y la arista \((u,w)\)
que minimizan \(T_k[u] + d(u, w)\) para cada arista candidata.</p>
</div>
</div>
<h3 id="rip-vector-de-distancia"><a class="header" href="#rip-vector-de-distancia">RIP (Vector de Distancia)</a></h3>
<ul>
<li>Cada nodo mantiene una tabla de distancias con tuplas de <code>(Dst, Cost, NextHop)</code>
<ul>
<li>Tiene la mejor distancia conocida a cada destino, y qué salida se usa
para llegar ahí</li>
</ul>
</li>
<li>Intercambia mensajes <strong>sólo con los vecinos directos</strong>
<ul>
<li>Esto ocurre periódicamente (cada ciertos segundos) o cuando su tabla
cambia por algún trigger.</li>
</ul>
</li>
<li>Cada actualización es una lista de pares <code>(Destination, Cost)</code></li>
<li>Se modifica la tabla si se recibe una <strong>mejor ruta</strong>
<ul>
<li>Tiene menor costo</li>
<li>Llegó desde el next-hop de ese destino</li>
</ul>
</li>
<li>Al igual que antes, tienen un timeout bajo el cuál se limpian las entradas de la tabla</li>
<li>Por qué se eligió Bellman-Ford distribuido en lugar de Dijkstra? Porque como
mencionamos, dijkstra consumía más cpu y memoria y al principio no había
tanto hardware que lo soporte (o se volvía muy caro).</li>
</ul>
<p>Algoritmo:</p>
<pre><code class="language-python">def receive_table(self, router_id, routing_table):
    for (destination, cost, next_hop) in self.routing_table:
        if destination == self.router_id: continue

        if routing_table[destination] + self.routing_table[router_id] &lt; cost:
            self.routing_table[destination] = (routing_table[destination] + self.routing_table[router_id], router_id)
</code></pre>
<p>En gral el costo lo medimos en nro. de saltos y listo. Al principio que tengo
nodos a los que no sé cómo llegar, los inicializo en infinito.</p>
<h4 id="qué-pasa-cuando-un-enlace-falla"><a class="header" href="#qué-pasa-cuando-un-enlace-falla">Qué pasa cuando un enlace falla?</a></h4>
<ul>
<li>caso feliz
<ul>
<li>falla el enlace de F a G. F lo detecta y setea su distancia a G a
infinito, y avisa a sus vecinos.</li>
<li>A se entera de eso y también setea su distancia a infinito.</li>
<li>A recibe una actualización de C con un camino a G en 2 saltos. Actualiza
su tabla para tener distancia de 3 saltos a G y manda la info a los
vecinos.</li>
<li>F recibe la actualización y setea su distancia a G en 4 saltos usando A.
<img src="./img/rip_happy_path.png" alt="" /></li>
</ul>
</li>
<li>caso triste (inestable, <strong>conteo a infinito</strong>)
<ul>
<li>falla el enlace de A a E. A le comunica a B y a C una distancia infinito
a E.</li>
<li>Tanto B como C antes de recibir el update de A comunican que llegan a E con distancia 2</li>
<li>Luego se les actualiza su distancia a infinito</li>
<li>Luego B decide que llega en 3 saltos a E a través de C y le avisa a A</li>
<li>A decide que llega en 4 saltos a E a través de B y le avisa a C</li>
<li>C decide que llega en 5 saltos a E a través de A</li>
<li>B decide que llega en 6 saltos a E a través de C</li>
<li>y así sucesivamente...</li>
<li>Esto está muy condicionado al timing en el que se reciben los mensajes.</li>
</ul>
</li>
</ul>
<p>Cómo lo resuelvo? Facilito: uso la heurística de que costo &gt; 16 lo setea como infinito</p>
<h4 id="formato-del-paquete"><a class="header" href="#formato-del-paquete">Formato del paquete</a></h4>
<ul>
<li>Comando</li>
<li>Version</li>
<li>Y una lista una atraz de la otra que contienen
<ul>
<li>red</li>
<li>tags</li>
<li>prefijo de red</li>
<li>mascara de red</li>
<li>distancia a la red</li>
</ul>
</li>
</ul>
<p><img src="./img/rip_packet.png#center" alt="" /></p>
<div id="admonition-sobre-qué-capa-corre-rip" class="admonition admonish-info">
<div class="admonition-title">
<p>Sobre qué capa corre RIP?</p>
<p><a class="admonition-anchor-link" href="unidad_5.html#admonition-sobre-qué-capa-corre-rip"></a></p>
</div>
<div>
<p>Uno podría pensar que RIP corre encapsulado sobre capa 3. Sin embargo, su
implementación es a nivel de aplicación y corre como un daemon usando UDP. Las
tablas de ruteo siguen en capa 3 pero el algoritmo y armado de las tablas
corren como una aplicación más.</p>
<p><img src="./img/rip_daemon.png#center" alt="" /></p>
</div>
</div>
<h3 id="ospf---open-shortest-path-first-link-state"><a class="header" href="#ospf---open-shortest-path-first-link-state">OSPF - Open Shortest Path First (Link State)</a></h3>
<ul>
<li>Todos los nodos tienen la misma info
<ul>
<li>O sea todos conocen la topología de la red gracias al mecanismo de
flooding (el flooding se hace dentro del sistema autónomo)</li>
</ul>
</li>
<li>Calculo el camino mínimo usando Dijkstra (forward search)</li>
<li>Algoritmo:
<ul>
<li>Descubro vecinos y sus direcciones de red</li>
<li>Mido el costo para cada vecino</li>
<li>Construyo un paquete con lo aprendido de los vecinos (Link State Packet,
<strong>LSP</strong>)
<ul>
<li>ID del router que lo creó</li>
<li>Costo del enlace a cada uno de sus vecinos</li>
<li>Número de secuencia (SEQNO)</li>
<li>TTL</li>
</ul>
</li>
<li>Mando el paquete a <strong>todos los demás routers</strong></li>
<li>Aplica Dijkstra y calcula la ruta más corta a todos los nodos</li>
</ul>
</li>
<li>Flooding: Cada router
<ul>
<li>Almacena el LSP más reciente de cada nodo</li>
<li>Decremena TTL
<ul>
<li>Descarta si TTL = 0</li>
<li>Manda un LSP ACK (por eso la inundación es confiable)
<ul>
<li>El protocolo reenvía los LSP que recibió a todos los que no le
mandaron el ACK (y tampoco el que le había mandado el paquete)</li>
</ul>
</li>
</ul>
</li>
<li>Reenvía LSP a todos los nodos menos el que envió el paquete recién
recibido</li>
<li>Genera LSP periodicamente e incrementa el SEQNO</li>
<li>Cuando se reinicia setea <code>SEQNO = 0</code></li>
</ul>
</li>
<li>En la práctica el algoritmo se maneja on the fly
<ul>
<li>Los registos son <code>(dstAddr, cost, next_hop)</code></li>
<li>Para eso se manejan dos listas:
<ul>
<li>tentativo</li>
<li>confirmado</li>
<li>En cada ciclo agrego entradas a la lista de tentativos, y el de menor
costo de todos los tentativos se pasa a confirmado. Una vez agregado
se recomputan los de la lista de tentativos.</li>
</ul>
</li>
</ul>
</li>
<li>A diferencia de RIP, OSPF está implementado sobre IP directamente.</li>
</ul>
<h4 id="ospf-jerárquico"><a class="header" href="#ospf-jerárquico">OSPF Jerárquico</a></h4>
<ul>
<li>Puedo dividir un sistema autónomo definiendo
<ul>
<li>varias "áreas" (pueden tener routers adentro)</li>
<li>un troncal de routers (un backbone)</li>
<li>routers de frontera de área que conectan el área con los troncales</li>
<li>un router frontera que sale hacia otro sistema autónomo</li>
</ul>
</li>
<li>El flooding se hace dentro de cada área, entonces saturo menos la red con
mensajes y hago más escalable a OSPF respecto de RIP</li>
</ul>
<h4 id="mensajes-de-ospf"><a class="header" href="#mensajes-de-ospf">Mensajes de OSPF</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Tipo de Mensaje</th><th>Descripción</th></tr></thead><tbody>
<tr><td>Hello</td><td>Sirve para descubrir los vecinos</td></tr>
<tr><td>Link State Update</td><td>Proporciona los costos del emisor a sus vecinos</td></tr>
<tr><td>Link State ACK</td><td>Confirma la recepción del update</td></tr>
<tr><td>Database description</td><td>Anuncia qué actualizaciones tiene el emisor</td></tr>
<tr><td>Link state request</td><td>Solicita información del socio</td></tr>
</tbody></table>
</div><div id="admonition-pregunta-de-final-alert" class="admonition admonish-warning">
<div class="admonition-title">
<p>PREGUNTA DE FINAL ALERT</p>
<p><a class="admonition-anchor-link" href="unidad_5.html#admonition-pregunta-de-final-alert"></a></p>
</div>
<div>
<p>Por qué decimos que OSPF realiza una inundación <strong>confiable</strong>?</p>
<ul>
<li>Porque el flooding se hace a todos los nodos del sistema autónomo</li>
<li>Y de cada nodo recibo el ack para asegurarme de que le llegó</li>
</ul>
</div>
</div>
<h4 id="paquete-de-ospf"><a class="header" href="#paquete-de-ospf">Paquete de OSPF</a></h4>
<p><img src="./img/ospf_header.png" alt="" /></p>
<p>Estoy mandando un paquete IP con el mismo formato que vimos en la unidad
anterior, en donde el campo de protocolo lleva el valor 89 para indicar que es
un paquete de OSPF. Además se usan algunos de los campos opcionales.</p>
<h3 id="bgp---ruteo-interdominio"><a class="header" href="#bgp---ruteo-interdominio">BGP - Ruteo Interdominio</a></h3>
<p>Generalidades:</p>
<ul>
<li>Diseñado para una red estructurada como árbol.</li>
<li>Prioriza <strong>alcanzar nodos</strong>, no optimiza rutas.</li>
</ul>
<p>Y para lograrlo usa los mensajes:</p>
<ul>
<li>Adequisición de vecinos: Pide a un router vecino ser su par, y los routers pares intercambian información de alcance.</li>
<li>Alcance de vecinos: mediante mensajes de <em>HELLO</em> y <em>ACK</em> chequean periódicamente que sus vecinos sigan siendo alcanzables.</li>
<li>Actualización de rutas: los routers intercambian periódicamente sus tablas de
ruteo.</li>
</ul>
<p>BGP resuelve el problema de evitar que los sistemas autónomos tengan que compartir info de alcanzabilidad entre ellos, manteniendo:</p>
<ul>
<li>cuáles rangos de direcciones IP se alcanzan en cada AS</li>
<li>por qué ruta se puede llegar de un AS <em>A</em> a un AS <em>B</em></li>
</ul>
<p><img src="./img/bgp.png" alt="" /></p>
<p>En este ejemplo podemos suponer que cada regional provider es un proveedor
(léase telecom, telefónica, etc.). Para llegar a USA, cómo hace Telecom? Va a
tener que pasar por el backbone, supongamos que es At&amp;t, que es un proveedor de
tier 1. Entonces, ese proveedor de tier 1 te va a cobrar por el servicio (que
sería publicar las rutas al resto del mundo, y además por cuánta data pasás).</p>
<p>Ahora, originalmente (~año 2000) el tráfico de acá se tenía que ir hasta USA
para volver a los servidores de acá. Se puede evitar eso? Surgen los NAP
(Network Access Point) o IX (Internet eXchanges).</p>
<ul>
<li>En Argentina tenemos la CABASE (Cámara Argentina de Internet)</li>
<li>Tienen uno o varios routers gigantes que interconectan varios ISPs locales.</li>
<li>2 beneficios, menos RTT y menor costo para el tráfico internacional</li>
</ul>
<p>Hoy en día, el tráfico internacional es bastante bajo porque el contenido está
almacenado localmente bajo CDNs (Content Distribution Networks).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unidad-6---nivel-de-transporte"><a class="header" href="#unidad-6---nivel-de-transporte">Unidad 6 - Nivel de Transporte</a></h1>
<ul>
<li>Llegamos a los primeros protocolos end-to-end, del nivel de transporte en
OSI.</li>
<li>El PDU en este nivel es el <strong>segmento</strong>.</li>
<li>A diferencia del nivel de enlace, el nivel de transporte no puede tener
conocimiento del delay (a priori).</li>
<li>Además tiene que lidiar con la congestión de la red</li>
<li>El modelo OSI normalmente piensa en el nivel de transporte como un modelo de
cliente-servidor.
<ul>
<li>Lo representamos con una máquina de estados (el diagrama en realidad es
el de TP4 pero está basado en TCP) <img src="./img/tp4_tcp.png" alt="" /></li>
</ul>
</li>
<li>TP4 es un protocolo basado en conexión</li>
<li>Ojo igual, no todos los protocolos son basados en conexión. Por ejemplo, UDP
es un servicio sin conexión y por lo tanto no tiene necesidad de mantener
toda esta máquina de estados.</li>
</ul>
<h2 id="protocolos-end-to-end-en-subredes-de-datagramas"><a class="header" href="#protocolos-end-to-end-en-subredes-de-datagramas">Protocolos end-to-end en subredes de datagramas</a></h2>
<ul>
<li>Los servicios de la capa de red son best-effort
<ul>
<li>se descartan mensajes,</li>
<li>pueden llegar desordenados</li>
<li>pueden haber duplicados</li>
<li>los mensajes tienen tamaño limitado</li>
<li>no hay un límite de tiempo para entregar mensajes</li>
</ul>
</li>
<li>Es por esto en parte que los protocolos end-to-end intentan proveer algunos
de los siguientes servicios:
<ul>
<li>garantía de entrega de mensajes</li>
<li>persistencia del orden</li>
<li>entrega de a lo sumo una copia de cada mensaje</li>
<li>soporte para mensajes arbitrariamente largos</li>
<li>soporte de sincronización (para los servicios con conexión)</li>
<li>permitir al receptor controlar el flujo de datos del transmisor</li>
<li>soportar varias aplicaciones al mismo tiempo en un mismo receptor</li>
</ul>
</li>
</ul>
<h2 id="tcp"><a class="header" href="#tcp">TCP</a></h2>
<p>Idea:</p>
<ul>
<li>2 Procesos: Cliente y Servidor</li>
<li>Uno escribe bytes en un puerto/socket</li>
<li>Hay un software tcp que tiene un buffer que almacena segmentos</li>
<li>Y se van mandando esos segmentos por la red (TCP entiende de segmentos pero
la aplicación <strong>manda y recibe bytes</strong>)</li>
<li>Full duplex (en ambos sentidos)
<ul>
<li>Tengo control de flujo: para que el Tx no inunde al Rx (ej: mandar
mensajes de "buffer lleno" para no overflowearlo)</li>
<li>Tengo control de congestión: para que el Tx no sobrecargue a la red</li>
</ul>
</li>
</ul>
<p>Algunas características:</p>
<ul>
<li>Orientado a conexión
<ul>
<li>Manejo de la conexión
<ul>
<li>3 way handshake para establecer la conexión</li>
<li>2-2 o 4-way handshake para la liberación de la conexión</li>
</ul>
</li>
<li>Provee un servicio de flujo de bytes (stream-of-bytes)</li>
</ul>
</li>
<li>Es <strong>confiable</strong> ya que tengo:
<ul>
<li>ACKs</li>
<li>Checksums</li>
<li>Números de secuencia para detectar datos perdidos / desordenados</li>
<li>Timeout para retransmitir datos</li>
<li>Se pueden reordenar los datos desordenados</li>
<li>Implementa <strong>Control de flujo</strong> para no inundar al receptor</li>
</ul>
</li>
</ul>
<h3 id="mms-maximum-segment-size"><a class="header" href="#mms-maximum-segment-size">MMS: "Maximum Segment Size"</a></h3>
<p>El segmento de tcp consiste de un header de al menos 20 bytes y la data que
está limitada al MMS (Maximum Segment Size, 536 bytes por default). Otra vez
podemos apreciar que el segmento tcp va a encapsularse en un paquete IP que a
su vez se encapsula en uno o más frames de ethernet.</p>
<p><img src="./img/tcp_segment.png#center" alt="" /></p>
<h3 id="formato-del-segmento"><a class="header" href="#formato-del-segmento">Formato del segmento</a></h3>
<p><img src="./img/tcp_segment_header.png#center" alt="" /></p>
<ul>
<li>Tengo puerto destino y fuente</li>
<li>Tengo campo de datos</li>
<li>Tengo nro. de secuencia</li>
<li>Nro de ACK</li>
<li>Flags</li>
<li>Aviso de ventana</li>
<li>Longitud del Header</li>
<li>Checksum
<ul>
<li>se calcula de forma "extraña": toma la data del segmento TCP + la
dirección fuente y destino de IP (se aplica a nivel 4 y toma algún dato
de la capa 3 también)</li>
</ul>
</li>
<li>Campos opcionales</li>
<li>Un par más</li>
</ul>
<p>Algunos detalles:</p>
<ul>
<li>los puertos son de 16 bits
<ul>
<li>las aplicaciones escuchan sobre algún puerto</li>
</ul>
</li>
<li>nro de secuencia de 32 bits. Identifica <strong>el primer byte de datos</strong></li>
<li>nro de ACK también de 32 bits. Identifica <strong>el siguiente byte que espera el
receptor</strong>
<ul>
<li>implica que llegó ese y todos los anteriores</li>
</ul>
</li>
<li>la longitud del header es de 4 bits y se mide en cantidad de palabras de 32
bits (necesitamos el campo porque hay campos de longitud variable).</li>
<li>El aviso de ventana indica cuántos bytes pueden ser enviados a partir del
último byte reconocido, permite evitar overflow en el buffer del receptor.</li>
</ul>
<h3 id="conexión-tcp"><a class="header" href="#conexión-tcp">Conexión TCP</a></h3>
<ul>
<li>Cada conexión se identifica con una 4-tupla <code>(srcPort, srcIPAddr, dstPort, dstIPAddr)</code></li>
<li>Usa un mecanismo de ventana deslizante + Control de Flujo
<ul>
<li>Mando con seqNum</li>
<li>hago el ack con seqNum + advertisedWindow</li>
</ul>
</li>
<li>Hay 5 flags: <code>SYN</code>, <code>FIN</code>, <code>RESET</code>, <code>PUSH</code>, <code>URG</code>, <code>ACK</code>
<ul>
<li><code>ACK = 1</code> se usa para marcar que estoy acknowledgeando algo (no se usa
para el setup y teardown de la conexión, si no mas bien para la recepción
de los datos)</li>
<li><code>RST</code> se usa para reiniciar una conexión</li>
<li><code>SYN</code> se usa para establecer la conexión, tanto para solicitar la
conexión como para avisar que fue aceptado el pedido.</li>
<li><code>FIN</code> se usa para liberar la conexión (especifica que el emisor no va a transmitir más datos).</li>
</ul>
</li>
</ul>
<p>Establecimiento de conexión:</p>
<p><img src="./img/three_way_handshake.png" alt="" /></p>
<p>Por qué hago el último ACK e incurrir en ese overhead? Para "resolver" <a href="https://stackoverflow.com/questions/36352236/two-general-agreement-and-tcp-handshake">el problema de los generales bizantinos</a></p>
<p>Liberación:</p>
<p><img src="./img/tcp_fin.png" alt="" /></p>
<p>Acá hago lo mismo para "asegurarme" que ambos liberaron sus recursos.</p>
<h3 id="tcp-ventana-deslizante"><a class="header" href="#tcp-ventana-deslizante">TCP: Ventana Deslizante</a></h3>
<p><img src="./img/tcp_sliding_window.png#center" alt="" /></p>
<ul>
<li>Para el receptor es todo igual salvo por el hecho de que el tamaño de la
ventana lo decide él mismo en base al espacio que le queda en su buffer</li>
<li>Y tanto para el emisor como el receptor tienen que atajarse al caso de
paquetes desordenados
<ul>
<li>El emisor mantiene 3 punteros: <code>LastByteAcked</code>, <code>LastByteSent</code> y <code>LastByteWritten</code>
<ul>
<li>A la derecha de <code>LastByteSent</code> tengo bytes generados pero no enviados</li>
</ul>
</li>
<li>El receptor mantiene <code>LastByteRead</code> (por la aplicación), <code>NextByteExpected</code>, <code>LastByteRcvd</code>. Entre <code>NextByteExpected</code> y  <code>LastByteRcvd</code> pueden haber baches.
<ul>
<li>La aplicación sólo puede leer un byte si todos los anteriores fueron recibido</li>
<li><code>AdvertisedWindow = MaxRcvBuffer - (LastByteRcvd - NextByteRead)</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="./img/advertised_window_example.png#center" alt="" /></p>
<h3 id="tcp-retransmisión-adaptativa"><a class="header" href="#tcp-retransmisión-adaptativa">TCP: Retransmisión Adaptativa</a></h3>
<div id="admonition-tema-de-final-alert" class="admonition admonish-warning">
<div class="admonition-title">
<p>Tema de Final ALERT</p>
<p><a class="admonition-anchor-link" href="unidad_6.html#admonition-tema-de-final-alert"></a></p>
</div>
<div>
</div>
</div>
<p>Cuando trabajabamos con la capa 2, podíamos calcular el timeout de
retransmisión porque asumíamos varias cosas (ej: distancia acotada). Pero acá,
puedo saber eso? A priori no. Porque no conozco el delay.</p>
<p>En 1988 Jacobson propone un mecanismo de control de congestión bajo el título
de <em>A fast algorithm for rtt mean and variation</em>.</p>
<p>Idea:</p>
<ul>
<li>Defino un timeout de retransmisión <strong>adaptativo</strong>, eso quiere decir que varía
en función del estado de la red (esta idea está basada en los conceptos de
<strong>lazo cerrado y teoría de control</strong>)</li>
<li>En capa 2 la función de densidad del RTT de ACK tiene poca varianza mientras
que en TCP tiene mucha.</li>
<li>Algoritmo original:
<ul>
<li>Mide <code>SampleRTTi</code> para cada par segmento / ACK</li>
<li>Calcula el promedio ponderado de RTT <code>EstimatedRTT_i+1 = alpha * EstimatedRTT_i + beta * SampleRTT_i+1</code>
<ul>
<li>alpha + beta = 1</li>
<li>alpha entre 0.8 y 0.9</li>
<li>beta entre 0.1 y 0.2</li>
<li>es un blend entre el RTT estimado y el sampleado</li>
</ul>
</li>
<li>Luego, <code>TimeOut =  2 * EstimatedRTT</code></li>
</ul>
</li>
<li>Pregunta: por qué me tomo todo este trabajo y no hago <code>TimeOut = SampleRTT_i-1</code>
<ul>
<li>porque no queda estable
<ul>
<li>es preferible algo suavizado para no ser suceptible a cambios muy
bruscos en la red.</li>
</ul>
</li>
</ul>
</li>
<li>Variante algoritmo de Karn/Partridge [KP87]
<ul>
<li>Problema: en realidad son 2:
<ul>
<li>Tengo que retransmitir, y calculo el RTT en base a la transmisión
original vs cuando me llega el ack en la retransmisión</li>
<li>Se cumple el Timeout, se re-envía e inmediatamente después llega el
ACK. El SampleRTT queda chico.</li>
</ul>
</li>
<li>Heurística: cuando hay retransmisión ignoro el RTT, si hay retransmisión
no lo estimo y duplico el último timeout conocido.</li>
</ul>
</li>
<li>Variante bis de Jacobson / Karels: usan un cálculo que considere la varianza
<ul>
<li><code>Diff = SampleRTT_i - EstRTT_i+1</code></li>
<li><code>EstRTT_i+1 = EstRTT_i + (delta * Diff)</code></li>
<li><code>Dev = Dev + sigma * (|Diff| - Dev)</code>
<ul>
<li>Sigma es un factor entre 0 y 1</li>
</ul>
</li>
<li><code>Timeout = mu * EstRTT + phi * Dev</code>
<ul>
<li>donde <code>mu = 1</code> y <code>phi = 4</code></li>
</ul>
</li>
<li>Timeout se acerca a <code>EstRTT</code> o a <code>Dev</code> dependiendo del valor dinámico de la varianza</li>
</ul>
</li>
</ul>
<p><img src="./img/karn_partridge.png#center" alt="" /></p>
<h3 id="tcp---sliding-window"><a class="header" href="#tcp---sliding-window">TCP - Sliding Window</a></h3>
<p>En capa 2 buscamos que el window size sea tal que estoy enviando durante todo
el RTT. Pero acá puede no pasar, y esto limita el throughput:</p>
<p><img src="./img/tcp_adaptative_window.png" alt="" /></p>
<p><code>MaxThroughput = WindowSize / RTT</code></p>
<p>TLDR: quiero siempre el "caño" lleno.</p>
<p>Ahora supongamos que tengo un <code>AdvertisedWindow</code> de 16 bits (o sea puedo mandar
hasta 64KB). Pero si tengo alguna tecnología razonable, el delay multiplicado
por el ancho de banda me va dando más y por ende se me hace cada vez más grande
ese espacio desaprovechado.</p>
<p>Para esto tengo un campo en las opciones del header que determina que el aviso
de ventana es en KBs en lugar de bytes.</p>
<h2 id="udp---servicio-sin-conexión"><a class="header" href="#udp---servicio-sin-conexión">UDP - Servicio Sin conexión</a></h2>
<ul>
<li>Tiene un header simple:
<ul>
<li>Puerto origen</li>
<li>Puerto destino</li>
<li>Longitud UDP</li>
<li>Checksum UDP (únicamente del header)</li>
</ul>
</li>
<li>El número de puerto de origen permite la <strong>multiplexación de procesos</strong>
<ul>
<li>nro de puerto + dirección IP = Socket</li>
<li>Notar que esto también ocurre en TCP, pero no es una feature muy
destacable para ese protocolo.</li>
</ul>
</li>
<li>En general, se monta RTP (Real Time Protocol) sobre UDP
<ul>
<li>Pero Netflix Opera corre sobre TCP via HTTP</li>
</ul>
</li>
</ul>
<h2 id="miscelaneous"><a class="header" href="#miscelaneous">Miscelaneous</a></h2>
<div id="admonition-something-something-quic" class="admonition admonish-info">
<div class="admonition-title">
<p>Something Something Quic</p>
<p><a class="admonition-anchor-link" href="unidad_6.html#admonition-something-something-quic"></a></p>
</div>
<div>
<p>Hace poco (2021) salió el standard para Quic, creado por Google que intenta ser un sucesor de TCP implementado sobre UDP:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/0B00TQ14faw?si=gy8gov_4CRVSvYAs&amp;start=609" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unidad-7---el-problema-de-congestión"><a class="header" href="#unidad-7---el-problema-de-congestión">Unidad 7 - El problema de Congestión</a></h1>
<div id="admonition-but-why-tho" class="admonition admonish-info">
<div class="admonition-title">
<p>But why tho?</p>
<p><a class="admonition-anchor-link" href="unidad_7.html#admonition-but-why-tho"></a></p>
</div>
<div>
<p>Inicialmente, Internet no tenía control de congestión. En el 84' ya se había
identificado la congestión como un potencial problema, sin embargo no fue hasta
el 86' que ocurrió un evento de congestión masivo por el cual la velocidad bajó
de 42kbps a 40bps, una reducción del 1000%!</p>
</div>
</div>
<p>Pensemos a nivel red hogareña, en donde tenemos varios dispositivos conectados
a la misma red, y todos salen por el mismo gateway (o router). Todos esos
dispositivos están constantemente compitiendo por recursos, un ejemplo sería el
buffer. Esto es lo que llamamos <strong>multiplexación estadística</strong> (es una
obviedad, pero no es únicamente el buffer de casa el que nos interesa. Esa
misma situación se puede dar en cualquier otro router).</p>
<ul>
<li>Cuando el buffer se llena, el router empieza a droppear paquetes</li>
<li>La congestión de todos modos es algo inevitable y nuestro mejor objetivo es
el de <strong>controlarlo</strong>, no eliminarlo.</li>
<li>Por qué no mejor evitarlo? Puedo conseguir routers con mayor buffer y listo.
El problema de eso es que a partir de cierto punto deja de ser rentable,
porque capaz en promedio no tenés mucha carga y el problema es que cada tanto
tenés picos de tráfico. Algo similar aplica a las autopistas, no las hago más
grandes porque sale caro y no es rentable.</li>
</ul>
<h2 id="administración-de-buffers"><a class="header" href="#administración-de-buffers">Administración de buffers</a></h2>
<ul>
<li>El Tanembaum hace referencia a congestión como algo global (que no es algo de
un punto) de la red</li>
<li>Pero nosotros consideramos tanto lo puntual como lo global. Tiene sentido
considerar lo puntual:</li>
</ul>
<p><img src="./img/individual_buffer.png#center" alt="" /></p>
<ul>
<li>Si el buffer se llena =&gt; aumenta el delay</li>
<li>Un buffer más grande puede llenarse más. Pero tengo que considerar que puede
aumentar el tiempo de procesamiento (aunque evito perder paquetes).</li>
</ul>
<p><strong>Definición</strong>: la <strong>congestión</strong> es un estado de sobrecarga sostenida en la cual:</p>
<ul>
<li>Tengo al límite la disponibilidad de enlaces o de buffers</li>
<li>Es observable porque se degrada el QoS</li>
</ul>
<h3 id="soluciones"><a class="header" href="#soluciones">Soluciones?</a></h3>
<ul>
<li>Sobredimensiono</li>
<li>Diseño cuidadosamente</li>
<li>Hago un control proactivo para evitar la congestión</li>
</ul>
<p>La solución es una suma de estas tres. En particular con el control proactivo
nos referimos a <strong>decrementar la carga</strong>. Quién decrementa la carga? Un
mecanismo de TCP llamado <em>control de congestión</em>.</p>
<h2 id="análisis-de-congestión"><a class="header" href="#análisis-de-congestión">Análisis de Congestión</a></h2>
<p><em>Teoría de colas</em>: disciplina matemática que explica el funcionamiento de las
colas y a problemas relacionados.</p>
<h3 id="sistema-mm1"><a class="header" href="#sistema-mm1">Sistema M/M/1</a></h3>
<p>Es un sistema cola-servidor (el servidor es el que se encarga de ir procesando
los paquetes encolados), en el cual el número de llegadas de paquetes es
markoviano (es un proceso de Poisson) y el tiempo de servicio (o sea el tiempo
que toma procesar un paquete) también es un Markoviano (en este caso un proceso
Exponencial) y donde asumimos que la cola tiene capacidad infinita. Llamamos
\(\lambda\) a la tasa de entrada y \(\mu\) a la tasa de servicio.</p>
<p><img src="./img/mm1_queue.png#center" alt="" /></p>
<p>Dado el tipo de esas variables aleatorias sabemos que \(\frac{1}{\lambda}\)
es el tiempo medio entre llegadas y \(\frac{1}{\mu}\) el tiempo medio de
servicio. Y definimos \(\rho = \frac{\lambda}{\mu}\) a la <strong>intensidad del
sistema</strong> Siempre que \(\rho &gt; 1\) el sistema eventualmente se desborda, o
sea que hay congestión (es razonable ya que no llegamos a atender a tiempo los
pedidos).</p>
<p>Usando una representación de Markov, se puede llegar a que \(E(N)\), la
esperanza de la ocupación del buffer y \(E(T)\), el tiempo de espera en el
sistema hasta ser procesado son:</p>
<p>$$
E(N) = \lambda * E(T) \\
E(T) = \frac{1}{\mu - \lambda}
$$</p>
<p>Y si pongo n servidores? A mayor cantidad de servidores mejora el tiempo de
respuesta (lo cual era razonable desde un principio). Sin embargo siempre tenés
una carga suficiente como para saturarte el sistema:</p>
<p><img src="./img/mmn_queue.png#center" alt="" /></p>
<h2 id="fundamentos"><a class="header" href="#fundamentos">Fundamentos</a></h2>
<p>Distintas definiciones de congestión:</p>
<ul>
<li>
<p>Tanembaum:</p>
<blockquote>
<p>Too many packets present in (a part of) the network causes packet delay
and loss that degrades performance. This situation is called congestion</p>
</blockquote>
</li>
<li>
<p>Peterson (habría que especificar a qué nos referimos con QoS, en gral. se
firman SLAs):</p>
<blockquote>
<p>Demasiadas fuentes usando una red compartida, enviando demasiados datos
demasiado rápido como para ofrecer una buena calidad de servicio.</p>
</blockquote>
</li>
<li>
<p>Síntomas típicos:</p>
<ul>
<li>pérdida de paquetes</li>
<li>retardo creciente</li>
</ul>
</li>
</ul>
<div id="admonition-warning" class="admonition admonish-warning">
<div class="admonition-title">
<p>Warning</p>
<p><a class="admonition-anchor-link" href="unidad_7.html#admonition-warning"></a></p>
</div>
<div>
<p>Control de congestion y control de flujo <strong>son dos problemas muy diferentes</strong></p>
<p>TCP define una ventana efectiva que es un resultado de ponderar la ventana de
control de flujo (el aviso de ventana) y el control de congestion.</p>
<ul>
<li>Control de flujo maneja una comunicación punto a punto</li>
<li>Control de congestión es algo que modifica toda una subred</li>
</ul>
</div>
</div>
<ul>
<li>Asumimos algunas cosas
<ul>
<li>Las colas son de tipo FIFO</li>
<li>Se descartan paquetes cuando se llena la capacidad como política de
manejo de buffers</li>
<li>simplificación: Si no llega ACK de TCP entonces hay congestión
<ul>
<li>Los libros hablan de que hay otras métricas (ej: % de paquetes
descartados, average packet delay) pero en la práctica no se tienen
en cuenta</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="políticas-que-influyen-en-la-congestión-por-capa"><a class="header" href="#políticas-que-influyen-en-la-congestión-por-capa">Políticas que influyen en la congestión por capa</a></h3>
<p>Notar que no sólo capa 4 influye si no que las anteriores también.</p>
<div class="table-wrapper"><table><thead><tr><th>Capa</th><th>Políticas</th></tr></thead><tbody>
<tr><td>Transporte</td><td>Política de retransmisión</td></tr>
<tr><td></td><td>Política de almacenamiento en caché de paquetes fuera de orden</td></tr>
<tr><td></td><td>Política de ACKs</td></tr>
<tr><td></td><td>Política de control de flujo</td></tr>
<tr><td></td><td>Determinación de terminaciones de temporizador</td></tr>
<tr><td>Red</td><td>Circuitos virtuales vs. datagramas en la subred</td></tr>
<tr><td></td><td>Política de encolamiento y servicio de paquetes</td></tr>
<tr><td></td><td>Política de descarte de paquetes</td></tr>
<tr><td></td><td>Algoritmo de enrutamiento</td></tr>
<tr><td></td><td>Administración de tiempo de vida del paquete</td></tr>
<tr><td>Enlace</td><td>Política de retransmisiones</td></tr>
<tr><td></td><td>Política de almacenamiento en caché de paquetes fuera de orden</td></tr>
<tr><td></td><td>Política de ACKs</td></tr>
<tr><td></td><td>Política de control de flujo</td></tr>
</tbody></table>
</div>
<h2 id="control-de-congestión"><a class="header" href="#control-de-congestión">Control de Congestión</a></h2>
<p>Consideramos como control de congestión a todo lo que hacen los nodos de la red
para prevenir o responder a sobrecargas de la red.</p>
<p>Mediante 3 métodologías:</p>
<ul>
<li>Pre-asignando recursos (a.k.a subutilizo)
<ul>
<li>ej: designo buffer específico para gaming, buffer especídixo para streaming, etc.</li>
</ul>
</li>
<li>Libero recursos</li>
<li>Controlo congestión sólo si ocurre (y cuando ocurre)
<ul>
<li>Tengo que decidir a quién "perjudicar"</li>
<li>Objetivo: permitir uso de recursos de forma "equitativa" (cuando hay congestión, todos se joden y fue)</li>
</ul>
</li>
</ul>
<h2 id="criterios-de-evaluación"><a class="header" href="#criterios-de-evaluación">Criterios de Evaluación</a></h2>
<ul>
<li>La idea es que la red sea usada de forma <strong>eficiente</strong> pero también <strong>equitativa</strong></li>
<li>Un buen indicador para la eficiencia: <code>potencia = throughput / delay</code></li>
<li>Indicador de equidad de Jain: dados \(n\) flujos por un enlace con throughputs \((x_1, x_2, \dots, x_n)\):</li>
</ul>
<p>$$
\frac{1}{n} \leq f \leq 1 \\
f(x_1, \dots, x_n) = \frac{(\sum_{i = 1}^n{x_i})^2}{n * \sum_{i = 1}^n{x_i^2}}
$$</p>
<ul>
<li>\(f = 1\) es cuando hay equidad máxima</li>
</ul>
<h2 id="teoría-de-control"><a class="header" href="#teoría-de-control">Teoría de control</a></h2>
<p>Un <strong>sistema de lazo cerrado</strong> es un sistema donde tomo una muestra de una
variable y en base a eso hago una acción.</p>
<ul>
<li>Ej: el aire acondicionado mide temperatura y en base a eso sigue o se apaga</li>
<li>En TCP el timeout de retransmisión lo calculábamos en base al RTT estimado,
que lo vemos como un sistema de lazo cerrado.</li>
</ul>
<p>Dentro de los sistemas de lazo cerrado, los podemos clasificar según el tipo de
retroalimentación:</p>
<ul>
<li><strong>retroalimentación implícita</strong>: que es lo que ocurre en TCP
<ul>
<li>la fuente infiere la congestión basado en Time-Outs, ACK duplicados</li>
</ul>
</li>
<li><strong>retroalimentación explícita</strong>: que es lo que ocurre en ICMP
<ul>
<li>packet marking</li>
<li>problema: necesito cooperación explícita entre fuentes y componentes de
red (switches). También debería cambiar los algoritmos de la fuente y los
nodos.</li>
<li>Hoy está volviendo a resurgir la idea de revivir los bits de CE
(Congestion Experienced) y ECN (ECN Capable Transport)</li>
</ul>
</li>
</ul>
<h2 id="red-random-early-detection"><a class="header" href="#red-random-early-detection">RED (Random Early Detection)</a></h2>
<ul>
<li>
<p>Propuesto por Jacobson</p>
</li>
<li>
<p>Método implícito de Congestion Avoidance</p>
</li>
<li>
<p>La idea es hacer una administración activa de la cola</p>
<ul>
<li>Está pensado para trabajar en colaboración com mecanismos de control de
congestión de la capa de transporte (en nuestro caso TCP)</li>
<li>En lugar de esperar a que se llene el buffer, cada tanto descarta un
paquete con cierta probabilidad, una vez superado un threshold de carga</li>
</ul>
<p><img src="./img/red.png#center" alt="" /></p>
</li>
<li>
<p>Algoritmo:</p>
<ul>
<li>Calculo largo promedio de la cola: <code>AvgLen = (1 - Weight) * AvgLen + Weight * sampleLen</code></li>
<li><code>Weight</code> es un escalar entre 0 y 1</li>
<li><code>SampleLen</code> es el tamaño de la cola, que se actualiza con cada paquete
que entra/sale</li>
<li>De alguna forma, <code>AvgLen</code> es una versión suavizada de <code>SampleLen</code>. Se
puede observar con el gráfico: <img src="./img/red_avg.png" alt="" /></li>
<li>Cuando llega un paquete evalúo el <code>AvgLen</code> y:
<ul>
<li>Si estoy por debajo de <code>MinThreshHold</code>, encolo siempre</li>
<li>Si estoy entre <code>MinThreshHold</code> y <code>MaxThreshHold</code>, descarto con una
probabilidad <code>p</code></li>
<li>Si estoy por arriba del <code>MaxThreshHold</code>, descarto siempre</li>
<li>esa probabilidad <code>p</code> se calcula como:
<ul>
<li><code>TempP = MaxP * (AvgLen - MinThreshHold) / (MaxThreshHold - MinThreshHold)</code></li>
<li><code>P = TempP / (1 - count * TempP)</code> con <code>count</code> el número de paquetes encolados</li>
</ul>
</li>
<li>si graficamos la probabilidad de droppear en función del valor de <code>AvgLen</code>:
<img src="./img/red_probability.png#center" alt="" /></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="impacto-del-cc-en-tcp"><a class="header" href="#impacto-del-cc-en-tcp">Impacto del CC en TCP</a></h2>
<ul>
<li>Vimos que RED está pensado para trabajar con el protocolo de transporte (en
este caso TCP).</li>
<li>Idea: defino una ventana de congestión
<ul>
<li>cuando pierdo un paquete, achico la ventana de congestión</li>
<li>genero una ventana efectiva de transmisión combinando la ventana de
congestión y el advertisedWindow. Entonces al achicar la ventana de
congestión, achico la ventana de transmisión (a costo de la Vtx).
<blockquote>
<p>Recuerdo: <code>Throughput = SWS * |frame| / RTT</code></p>
</blockquote>
</li>
<li>Regulo la ventana de congestión: la seteo en 1 y va creciendo de forma exponencial (slow start)</li>
</ul>
</li>
</ul>
<h3 id="slow-start"><a class="header" href="#slow-start">Slow Start</a></h3>
<p>Por cada RTT hago:</p>
<ul>
<li>Si recibo un ACK: <code>W &lt;- (W+1)/ W</code>.</li>
<li>Si se pierde un ACK: <code>W &lt;- W / 2</code></li>
</ul>
<p><img src="./img/slow_start_window.png#center" alt="" /></p>
<h4 id="performance-de-tcp"><a class="header" href="#performance-de-tcp">Performance de TCP</a></h4>
<ul>
<li>Asumo que tengo un flujo TCP</li>
<li>Tengo RTT constante</li>
<li>Tengo prob p de pérdida de paquetes</li>
<li>Tengo un ancho de banda relativamente grande (lo que nos importa es que es lo
suficientemente grande como para llenar el buffer)</li>
<li>La señal de congestión es periódica</li>
</ul>
<p>Me pregunto: cuál es el throughput de la conexión TCP</p>
<ul>
<li>Cuántos paquetes por ciclo?</li>
<li>Cuál es la duración de un ciclo?</li>
</ul>
<p>Fórmula final:</p>
<p>$$
BW = \frac{MSS * C}{RTT * \sqrt{p}} \\
C = \sqrt{\frac{3}{2}}
$$</p>
<p><img src="./img/formula_throughput_tcp.png" alt="" /></p>
<ul>
<li>la escala es doble logarítmica</li>
<li>\(MSS\) es el tamaño máximo de segmento (puede estár acotado por el MTU del
enlace de salida desde el host), no incluye los headers de TCP e IP.</li>
<li>conclusión: TCP está limitado por el RTT</li>
</ul>
<h2 id="moralejas"><a class="header" href="#moralejas">Moralejas</a></h2>
<ul>
<li>La congestión es un fenómeno que siempre aparece.</li>
<li>TCP implementa control de congestión e2e.</li>
<li>lo vemos como un sistema de control de lazo cerrado con retroalimentación
implícita.</li>
<li>control de congestión en TCP: defino ventana de congestión que junto con el
aviso de ventana defino una ventana de transmisión. Esa ventana al perder un
paquete decremento y al recibir un ACK incremento.</li>
<li>el control de congestión hace que el throughput sea constantemente variable.</li>
<li>Qué hace por ejemplo Netflix cuando hay congestión y baja el throughput?
<ul>
<li>baja la calidad de la imagen (<a href="https://en.wikipedia.org/wiki/Dynamic_Adaptive_Streaming_over_HTTP">Dash</a>)</li>
<li>usa CDNs para bajar el RTT y aumentar el throughput</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unidad-8---nivel-de-aplicación"><a class="header" href="#unidad-8---nivel-de-aplicación">Unidad 8 - Nivel de Aplicación</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unidad-9---seguridad"><a class="header" href="#unidad-9---seguridad">Unidad 9 - Seguridad</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bibliografía"><a class="header" href="#bibliografía">Bibliografía</a></h1>
<p>Libro de Cabecera de la materia:</p>
<ul>
<li>Larry L. Peterson and Bruce S. Davie. 2011. Computer Networks, Fifth edition: A Systems Approach. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.</li>
</ul>
<p>Libro complementario que no vimos en la materia pero me pareció didáctico:</p>
<ul>
<li><a href="https://catnip.article19.org/">How The internet really works - An Illustrated Guide to protocols, privacy, censorship, and governance</a></li>
</ul>
<h2 id="miscelaneous-1"><a class="header" href="#miscelaneous-1">Miscelaneous</a></h2>
<ul>
<li><a href="https://fermatslibrary.com/s/why-the-internet-only-just-works">why the internet only just works - Fermat's Library</a></li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </div>
    </body>
</html>
